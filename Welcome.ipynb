{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Jupyter Notebooks on the Intel DevCloud for oneAPI Projects! \n",
    "This document covers the basics of the JupyterLab access to the Intel DevCloud for oneAPI Projects. It is not a tutorial on the JupyterLab itself. Rather, we will run through a few examples of how to use the computational resources available on the DevCloud *beyond* the notebook.\n",
    "\n",
    "The diagram below illustrates the high-level organization of the DevCloud. This tutorial explains how to navigate this organization. \n",
    "\n",
    "<img src=\"https://devcloud.intel.com/oneapi/static/images/svg/cluster-jn-organization.svg\" style=\"max-width:600px;\" />\n",
    "\n",
    "\n",
    "## Service Terms\n",
    "\n",
    "By using the Intel DevCloud for oneAPI Projects, you are agreeing to the terms linked in the footer of the Intel DevCloud website: <br />\n",
    "<a href=\"https://devcloud.intel.com/oneapi/\">https://devcloud.intel.com/oneapi/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Notebook Basics](#sec-basics)\n",
    "2. [Compute Power and Limits](#sec-limits)\n",
    "3. [Job Queue](#sec-queue)\n",
    "4. [Final Words](#sec-final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-basics\"></a>\n",
    "## 1. Notebook Basics\n",
    "\n",
    "You can find detailed documentation on using the JupyterLab software at <a href=\"https://jupyter.org/\">jupyter.org</a>. For our tutorial, you just need to know that \n",
    "- When you see cells like below (the line that begins with `!echo \"Running...\"`), this is code that you can run. \n",
    "- If you mouse-click on the cell, you will be able to edit the code. \n",
    "- While you are in the cell, press Ctrl+Enter, and the code in the cell will run.\n",
    "- In the top-right corner of the page, the indicator ○ will change to ●. This means that the kernel is busy. \n",
    "- If the code begins with \"!\", it will run in the Bash shell. Otherwise, it is treated as Python code.\n",
    "\n",
    "Go ahead, click the cell below and then press Ctrl+Enter. You should see \"Running...\" and a few seconds later \"...done\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Running...\"; sleep 3; echo \"...done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"sec-limits\"></a>\n",
    "## 2. Compute Power and Limits\n",
    "For the most part, the Notebook session on the DevCloud should be familiar to JupyterLab users. However, there are few limitations that you should be aware of.\n",
    "\n",
    "* ### Session Time\n",
    " Your JupyterLab session has a time limit. \n",
    " If your session runs out of time, you can start a new one by refreshing the page or going to <a href=\"https://jupyter.oneapi.devcloud.intel.com\">jupyter.oneapi.devcloud.intel.com</a> again. However, keep in mind that\n",
    " * The contents of the Notebook will not be automatically saved when the session time runs out. Save your work!\n",
    " * All running processes (the notebook itself, the kernels running in it, terminals) are terminated. If you want to run calculations that survive outside the notebook, use the <a href=\"#sec-queue\">job queue</a> as described below.\n",
    "\n",
    "* ### Number of Cores\n",
    " Your Notebook is running on a powerful computing server, but other people may be running Notebooks on the same server. They cannot access your files, but you do share the pool of the CPU cores. For heavy workloads (e.g., neural network training), you can get access to more computing power by submitting scripts to the <a href=\"#sec-queue\">job queue</a> as discussed below.\n",
    " \n",
    "* ### Amount of Memory\n",
    " Your Notebook is also sharing the computing server's operating memory with other tenants. If you need more memory for calculations, use the <a href=\"#sec-queue\">job queue</a>.\n",
    " \n",
    "Run the code in the cell below to query the limits of your JupyterLab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"* How many seconds are left in my JupyterLab session?\"\n",
    "!qstat -f $PBS_JOBID | grep Walltime.Remaining\n",
    "\n",
    "!echo \"* How many logical CPUs do I have for the Notebook?\"\n",
    "!taskset -c -p $$\n",
    "\n",
    "!echo \"* How much RAM can I use in the Notebook?\"\n",
    "!/usr/local/bin/qstat -f $PBS_JOBID | grep vmem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"sec-queue\"></a>\n",
    "## 3. Job Queue\n",
    "The job queue is the only method for accessing the full capacity of the computing resources available on the DevCloud. This section explains how you can interact with the queue from the JupyterLab environment. You can also submit to the queue from a terminal session. A more detailed guide on queue usage is available on the <a href=\"https://devcloud.intel.com/oneapi/learn/job-submission/\">Intel DevCloud website</a>.\n",
    "\n",
    "\n",
    "### Creating a Job Script\n",
    "To submit a job to the queue, create a Bash script containing the commands that you want to run. \n",
    "You can do this from the Notebook using the `%%writefile` magic. The following example creates a job script called `hello-world-example`. The line `cd $PBS_O_WORKDIR` changes the working directory to the directory where the script is located. Everything else runs in the Bash shell on the designated compute server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hello-world-example\n",
    "cd $PBS_O_WORKDIR\n",
    "echo \"* Hello world from compute server `hostname`!\"\n",
    "echo \"* The current directory is ${PWD}.\"\n",
    "echo \"* Compute server's CPU model and number of logical CPUs:\"\n",
    "lscpu | grep 'Model name\\\\|^CPU(s)'\n",
    "echo \"* Python available to us:\"\n",
    "which python\n",
    "python --version\n",
    "echo \"* The job can create files, and they will be visible back in the Notebook.\" > newfile.txt\n",
    "sleep 10\n",
    "echo \"*Bye\"\n",
    "# Remember to have an empty line at the end of the file; otherwise the last command will not run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see the file `hello-world-example` when you go to the tree menu, or if you run the `%ls` magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only Bash job scripts are supported. If you need to run a Python application, add the corresponding Python launch line to the job script. For example:\n",
    "\n",
    "    %%writefile my_job_script\n",
    "    echo \"Running myapplication.py\"\n",
    "    python myapplication.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting a Job to the Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can submit this script as a job using the `qsub` command. Go ahead and execute the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qsub hello-world-example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have submitted a job to the queue. You should see an output line that looks like \"[numbers].cXXX\". \n",
    "The number you see in the front is the Job ID. We will be using this number to retrieve the output of the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Queue Status\n",
    "Once the job has been placed in the queue, you can find the current status of the job by running the followng command in a cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran `qstat` soon enough, you will see a job with the name `...world-example`. In the column `S` you will see a letter indicating its status: \"Q\" is for \"queued\", \"R\" is for \"running\", and \"E\" is either an error, or a transition to a normal job completion. If you still see an entry for `...world-example`, keep re-running the above cell a few times until the \"hello world\" job completes and disappears from the list. If you don't see this entry, proceed to the next section to view the results of our job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the result\n",
    "Once the job is completed, the resulting output and error streams (stdout and stderr) are placed in two seperate text files. These output files have the following naming convention: \n",
    "\n",
    "* stdout: [Job Name].o[Job ID].    Example: `hello-world-example.o12345`\n",
    "* stderr: [Job Name].e[Job ID].    Example: `hello-world-example.e12345`\n",
    "\n",
    "[Job Name] is either the script name, or a custom name — for example, the name specified by the `-N` parameter of `qsub`. \n",
    "\n",
    "[Job ID] is the number you got from the output of the `qsub` command. \n",
    "\n",
    "Let's find the output file produced by the `hello-world-example` job by running the `%ls` magic again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls hello-world-example*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view this file, you can go to File -> Open... click on the `hello-world-example.o*` file. Alternatively, you can view the contents of the file inside the JupyterLab using the `%cat` magic command. Run the cell below to view the result of the \"hello world\" job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat hello-world-example.o*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error stream goes to the .e* files. For our job, it is empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat hello-world-example.e*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, any files created by the job will be visible after its completion. Useful for data processing tasks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat newfile.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colfax Magic for Job Submission\n",
    "\n",
    "We have created a custom cell magic command `%%qsub` to simplify job submission from Notebooks. \n",
    "The magic is defined as a part of the `cfxmagic` module. You can use it after you have imported the module. Run the cells below to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile PythonDemo.py\n",
    "# Creating an example Python application. \n",
    "# You can do it with the %%writefile magic like we are doing here,\n",
    "# or you can go to the File menu, choose Open, and from there\n",
    "# either upload your code or create a .py file and compose it in the Notebook\n",
    "print (\"Hello world from Python!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cfxmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%qsub\n",
    "cd $PBS_O_WORKDIR\n",
    "python PythonDemo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will submit the contents of the cell as a job named STDIN, without writing the script into a separate file. \n",
    "\n",
    "Wait a few moments and then view the output of the job by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls STDIN.*\n",
    "%cat STDIN.o*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Parameters\n",
    "Both the `!qsub <file>` command and the `%%qsub` magic can take a variety of parameters that you can set. For example, the following command requests a wall clock time limit of 24 hours and passes a command line argument equal to \"13.2\" to the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qsub hello-world-example -l walltime=24:00:00 -F \"13.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qmgr -c 'p q batch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting Multiple Jobs\n",
    "\n",
    "You can submit a number of jobs at once. If enough compute servers are available, all jobs will run simultaneously. Otherwise, they will stay in the queue waiting for their turn to run. \n",
    "\n",
    "When you submit a lot of jobs, be aware that the queue has a fair share-based scheduling policy, so the more you run, the more often will your jobs yield to other users' calculations.\n",
    "\n",
    "You can learn about the pool of compute servers available for your jobs by running the commands below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"* How many compute servers are available?\"\n",
    "!pbsnodes | grep \"^s\" | wc -l\n",
    "\n",
    "!echo \"* How many of them are free?\"\n",
    "!pbsnodes | grep \"state = free\" | wc -l\n",
    "\n",
    "!echo \"* What are the time limits for queued jobs?\"\n",
    "!qmgr -c 'p q batch' | grep walltime\n",
    "\n",
    "!echo \"* What is the configuration of the available compute servers?\"\n",
    "!pbsnodes | grep properties | sort | uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Running the JupyterLab Code as a Job\n",
    "JupyterLab sessions are designed for interactive computing, which is the opposite of what the job queue is designed for. However, if you structured your Jupyter Notebook code as non-interactive Python application, you can submit your code to the queue. \n",
    "\n",
    "For example, suppose that your Notebook \n",
    "1. Imports some Python modules, \n",
    "2. Loads a dataset, \n",
    "3. Sets up a neural network\n",
    "4. Trains it, and \n",
    "5. Writes the resultant model weights into a file. \n",
    "This is the kind of workload that can benefit from access to a powerful compute server and does not require interactivity. Therefore, you can submit it to the job queue. \n",
    "\n",
    "You can dump the code of all cells in a Notebook into a Python script using the `jupyter` command shown below. Suppose that you have a Notebook saved in the file `mynotebook.ipynb`. The following cell converts the Notebook into a Python script `mynotebook.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not try to run this unless you already have a file called mynotebook.ipynb\n",
    "# This is just an illustration.\n",
    "!jupyter nbconvert --to script \"mynotebook.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will view the resultant Python code mynotebook.py\n",
    "!cat \"mynotebook.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above commands should have created a Python script named `mynotebook.py`. You can submit this script to the queue as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not submit; this is an illustration.\n",
    "%%qsub\n",
    "cd $PBS_O_WORKDIR\n",
    "python mynotebook.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"sec-final\"></a>\n",
    "## 4. Final Notes\n",
    "This document covered some of the basics of using the JupyterLab environment on the DevCloud. \n",
    "\n",
    "JupyterLab is not the only way to access the DevCloud. You can also log in with an SSH client or a file transfer application based on the SSH protocol (e.g., WinSCP or FileZilla). This may be a more convenient access mode for advanced users who already have the code base developed, and who want to execute their code on powerful compute resources.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.2)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
