/******************************************************************************

    Copyright (C) 2002-2021 Codeplay Software Limited
    All Rights Reserved.

    Codeplay's ComputeCpp

*******************************************************************************/

/**
  @file apis.h

  @brief This file contains functions that are used to invoke kernels
*/
#ifndef RUNTIME_INCLUDE_SYCL_APIS_H_
#define RUNTIME_INCLUDE_SYCL_APIS_H_

#include "SYCL/accessor.h"
#include "SYCL/base.h"
#include "SYCL/buffer.h"
#include "SYCL/common.h"
#include "SYCL/context.h"
#include "SYCL/event.h"
#include "SYCL/group.h"
#include "SYCL/id.h"
#include "SYCL/index_array.h"
#include "SYCL/interop_handle.h"
#include "SYCL/kernel.h"
#include "SYCL/nd_range_base.h"
#include "SYCL/predefines.h"
#include "SYCL/program.h"
#include "SYCL/range.h"
#include "SYCL/reduction.h"
#include "SYCL/task.h"
#include "SYCL/type_traits.h"

#ifdef __SYCL_DEVICE_ONLY__
#include "SYCL/compiler_hooks.h"  // for kernelgen_* functions
#endif

#include <array>
#include <cstddef>
#include <functional>
#include <memory>
#include <type_traits>
#include <utility>
#include <vector>

#include "computecpp_export.h"

namespace cl {
namespace sycl {
#ifndef __SYCL_DEVICE_ONLY__
class accessor_base;
#else
template <typename T>
class accessor_device_base;
using accessor_base = accessor_device_base<void*>;
#endif

namespace detail {

class enqueue_device_kernel_command;
class queue;
class transaction;

/** @brief Given a lambda and a template parameter with a name, creates a
 * typedef which will define the kernel name used by the device compiler.
 */
template <typename functorT, typename nameT>
struct enable_functor {
  using kernel_name = nameT;
};

/** @brief Specialization of the enable_functor for when the user passes a
 * functor. This way, the kernel name is not defined if the user has given a
 * functor (as the name of the kernel is the name of the functor).
 */
template <typename functorT>
struct enable_functor<functorT, std::nullptr_t> {
  using kernel_name = functorT;
};

/** @brief Forward declaration of the helper struct for handler::set_args
 */
template <typename... Ts>
struct set_args_helper;

}  // namespace detail

namespace codeplay {
class host_handler;
class handler;
}  // namespace codeplay

}  // namespace sycl
}  // namespace cl

#ifndef __SYCL_DEVICE_ONLY__

namespace cl {
namespace sycl {

/**
 * @brief A handler gives user access to command group scope functionality,
 * such as API calls. This simplifies the interface, as the command group class
 * is not required anymore and the scope is explicit for accessors and API
 * entries.
 *
 * It is also used by accessors to get the current command group scope.
 * Handlers can only be constructed from within queues.
 * For the time being, the deprecated command group function also can create
 * handlers.
 *
 * The templated-side of the API entries is defined here.
 * Some API entries are explicitly deleted to shield users from weird template
 * errors caused by enable_if macros. In particular, if there is a pointer to a
 * kernel instead of a kernel, the template deduction fails and causes a massive
 * template error. However, using the deleted API entry the user sees an
 * explicit error because they are using a non-valid interface.
 */
class COMPUTECPP_EXPORT handler {
  /**
   *@brief Maximum number of kernels that a command group can contain.
   *Implementation and specification currently only support a single
   *kernel.
   */
  const unsigned MAX_KERNELS_PER_CG = 1u;

  friend class queue;
  friend class detail::queue;
  friend class codeplay::host_handler;
  friend class codeplay::handler;

  /**
   @brief Type of a function that sets a parameter to a kernel.
  */
  using add_param_func_t = function_class<void(kernel&, handler&)>;

  /**
  @brief Sets the current list of parameters to the given kernel.
  */
  void set_parameters(kernel& syclKernel);

  /** @cond COMPUTECPP_DEV */

  /** @brief Rudimentary check whether passed function object has the same
   * record layout as its mirror struct generated by the device compiler.
   * The primary template co-functions as the default case if there are no
   * kernel arguments and there is no mirror struct present.
   */
  template <typename kernelName, typename functorT, typename mirrorT = void>
  struct is_kernel_layout_compatible : std::true_type {};

  /** @brief Specialization in case a mirror struct is detected in kernel_info -
   * do the sanity check. */
  template <typename kernelName, typename functorT>
  struct is_kernel_layout_compatible<
      kernelName, functorT,
      detail::void_t<typename detail::kernel_info<kernelName>::mirror_type_0>>
      : detail::bool_constant<
            sizeof(functorT) ==
                sizeof(
                    typename detail::kernel_info<kernelName>::mirror_type_0) &&
            alignof(functorT) ==
                alignof(
                    typename detail::kernel_info<kernelName>::mirror_type_0)> {
  };

  /** @endcond COMPUTECPP_DEV */

  /**
  @brief Gets the parameters from a functor and set them as OpenCL parameters.
  @tparam functorT Functor
  @param cl::sycl::kernel SYCL Kernel associated with the functor
  @param currentCommand Internal command object
  */
  template <typename kernelName, typename functorT>
  inline void process_functor_arguments(
      const functorT& functor,
      cl::sycl::kernel& syclKernel,  // NOLINT
      detail::enqueue_device_kernel_command* currentCommand) {
    if (this->get_context().is_host()) {
      // Don't process OpenCL arguments for host device
      return;
    }

    detail::functor_arg_descriptor argDesc = get_args_descriptor<kernelName>();

    // gcc < 5 always picks the specialized type trait - skip sanity check.
#ifndef COMPUTECPP_GCC_PRE_5
    static_assert(
        is_kernel_layout_compatible<kernelName, functorT>::value,
        "The kernel argument memory layout of " COMPUTECPP_HOST_COMPILER_STRING
        " is not compatible "
        "with the device compiler. "
        "Try to use -sycl-driver instead.");
#endif

    process_functor_arguments_impl(
        syclKernel, reinterpret_cast<detail::binary_address>(&functor), argDesc,
        currentCommand);
  }

  /**
  @brief Gets the arguments descriptor for the provided kernel.

  If the kernel has arguments, the binary info will be queried (and must exist).
  If the kernel needs no arguments, this is skipped, and an arg descriptor with
  no elements is returned.

  @tparam kernelName The kernel to get arguments for
  @return An arguments descriptor describing argument kinds and usage
  */
  template <typename kernelName>
  inline detail::functor_arg_descriptor get_args_descriptor() const {
    using info = detail::kernel_info<kernelName>;

    if (std::tuple_size<decltype(info::bin_info[0].arguments)>::value > 0) {
      auto& binInfo = cl::sycl::program::select_kernel_binary_info_helper(
          info::bin_info, info::bin_count, this->get_device_weak());

      return detail::functor_arg_descriptor(info{}, binInfo.arguments.data(),
                                            binInfo.arguments.size());
    } else {
      return detail::functor_arg_descriptor(info{}, nullptr, 0);
    }
  }

  /** Sets the numBytes from memory pointed at by @p ptr to given value
   * interpreted as an unsigned char.
   * @param ptr Pointer to the memory location to write to.
   * @param value The value to set memory to. static_cast to unsigned char.
   * @param numBytes The number of bytes to set from ptr
   */
  void memset_impl(void* ptr, int value, size_t numBytes);

 public:
  /**
  @brief Destructor of the handler, implementation on the cpp file
  so the default_deleter can see the implementation of the internal
  transaction object.
  */
  COMPUTECPP_TEST_VIRTUAL ~handler();
  /** @cond COMPUTECPP_DEV */
  /**
  @brief Returns an internal transaction
  */
  detail::transaction* get_transaction() const;

  /**
  @brief Returns an internal transaction only
  */
  dtrans_uptr&& move_transaction();

  /** @endcond */
  /**
  @brief Sets an argument when using interop kernels
  */
  template <typename T>
  void set_arg(int param_num, T&& param) {
    if (m_paramVec.size() <= static_cast<unsigned int>(param_num)) {
      m_paramVec.resize(param_num + 1);
    }

    add_param_func_t pf = [param_num, param](kernel& k, handler& h) {
      k.set_arg(param_num, param, h);
    };

    m_paramVec[param_num] = pf;
  }

  /** @brief Set all the given kernel args arguments for an OpenCL kernel,
   *        as if set_arg() was used with each of them in the same order
   *        and increasing index always starting at 0.
   * @tparam Ts Types of the parameters passed to the OpenCL kernel
   * @param args Parameters passed to the OpenCL kernel
   */
  template <typename... Ts>
  void set_args(Ts&&... args) {
    detail::set_args_helper<Ts...>::apply(*this, 0, std::forward<Ts>(args)...);
  }

  /////////////// API : Single Task

  /**
  @brief This function effectively just launches a single thread
  to execute the kernel in serial asynchronously to the host execution.
  This function takes in a precompiled kernel @ref syclKernel previously
  created using @ref build_with_kernel_type or @ref compile_with_kernel_type
  @param syclKernel The precompiled kernel to be enqueued
  */
  void single_task(kernel syclKernel);

  /** @cond COMPUTECPP_DEV */
  void single_task(kernel* syclKernel) = delete;

  template <typename kernelName, typename functorT>
  void single_task_impl(const functorT& functor) {
    program p(
        program::create_program_for_kernel<kernelName>(this->get_context()));
    kernel syclKernel(p.get_kernel<kernelName>());

    auto currentCommand = this->create_kernel_command_group(syclKernel);

    this->process_functor_arguments<kernelName, functorT>(functor, syclKernel,
                                                          currentCommand);

    this->execute_kernel_single_task_ptr(
        nd_range<3>(range<3>(1, 1, 1), range<3>(1, 1, 1), id<3>()), syclKernel,
        functor, currentCommand);
  }

  template <typename kernelName, typename functorT>
  void single_task_impl(kernel syclKernel, const functorT& functor) {
    auto currentCommand = this->create_kernel_command_group(syclKernel);

    this->process_functor_arguments<kernelName, functorT>(functor, syclKernel,
                                                          currentCommand);
    this->execute_kernel_single_task_ptr(
        nd_range<3>(range<3>(1, 1, 1), range<3>(1, 1, 1), id<3>()), syclKernel,
        functor, currentCommand);
  }
  /** @endcond */

  /**
  @brief This function effectively just launches a single thread
  to execute the kernel in serial asynchronously to the host execution.
  @tparam nameT The name of the kernel being enqueued
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT>
  void single_task(const functorT& functor) {
    single_task_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        functorT>(functor);
  }

  /**
  @brief This function effectively just launches a single thread
  to execute the kernel in serial asynchronously to the host execution.
  This function takes in a precompiled kernel @ref syclKernel previously
  created using @ref build_with_kernel_type or @ref compile_with_kernel_type
  @tparam nameT The name of the kernel being enqueued
  @param syclKernel The precompiled kernel to be enqueued
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT>
  void single_task(kernel syclKernel, const functorT& functor) {
    single_task_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        functorT>(syclKernel, functor);
  }

  /////////////// API : Parallel For

  /**
  @brief Parallel_for will enqueue the precompiled kernel @ref syclKernel to be
  executed
  a number of instances working in parallel over the number of local and global
  work items specified
  by @ref ndRange.
  @tparam dimensions Number of dimensions of the kernel
  @param ndRange Dimensions of the global and local work groups
  @param syclKernel The precompiled kernel to be enqueued
  */
  template <int dimensions>
  void parallel_for(const nd_range<dimensions>& ndRange, kernel syclKernel) {
    this->parallel_for_impl(static_cast<const detail::nd_range_base&>(ndRange),
                            syclKernel, dimensions);
  }

  /**
  @brief Parallel_for will enqueue the precompiled kernel @ref syclKernel to be
  executed a number of
  instances working in parallel over the number of global work items specified
  by @ref range.
  @tparam dimensions Number of dimensions of the kernel
  @param range Dimensions of the global work group
  @param syclKernel The precompiled kernel to be enqueued
  */
  template <int dimensions>
  void parallel_for(const range<dimensions>& range, kernel syclKernel) {
    this->parallel_for_impl(static_cast<const detail::index_array&>(range),
                            detail::index_array(0, 0, 0), syclKernel,
                            dimensions);
  }

  /**
  @brief Parallel_for will enqueue the precompiled kernel @ref syclKernel to be
  executed a number of
  instances working in parallel over the number of global work items specified
  by @ref range.
  @tparam dimensions Number of dimensions of the kernel
  @param range Dimensions of the global work group
  @param offset The offset into the data being executed
  @param syclKernel The precompiled kernel to be enqueued
  */
  template <int dimensions>
  void parallel_for(const range<dimensions>& range, id<dimensions> offset,
                    kernel syclKernel) {
    this->parallel_for_impl(static_cast<const detail::index_array&>(range),
                            static_cast<const detail::index_array&>(offset),
                            syclKernel, dimensions);
  }

  /** @cond COMPUTECPP_DEV */

  template <int dimensions>
  void parallel_for(const range<dimensions>& range,
                    kernel* syclKernel) = delete;
  template <int dimensions>
  void parallel_for(const range<dimensions>& range, id<dimensions> offset,
                    kernel* syclKernel) = delete;

  template <int dimensions>
  void parallel_for(const nd_range<dimensions>& ndRange,
                    kernel* syclKernel) = delete;

  void parallel_for_impl(const detail::index_array& range, kernel syclKernel,
                         int dimensions);

  void parallel_for_impl(const detail::index_array& range,
                         const detail::index_array& offset, kernel syclKernel,
                         int dimensions);

  void parallel_for_impl(const detail::nd_range_base& ndRange,
                         kernel syclKernel, int dimensions);

  template <typename kernelName, typename functorT>
  void parallel_for_impl(const detail::nd_range_base& ndRange,
                         const functorT& functor, int dimensions) {
    program p(
        program::create_program_for_kernel<kernelName>(this->get_context()));
    kernel syclKernel(p.get_kernel<kernelName>());

    auto currentCommand = this->create_kernel_command_group(syclKernel);

    this->process_functor_arguments<kernelName, functorT>(functor, syclKernel,
                                                          currentCommand);

    this->execute_kernel_parallel_for_ptr(ndRange, syclKernel, functor,
                                          currentCommand, dimensions);
  }

  template <typename kernelName, typename functorT>
  void parallel_for_impl(kernel syclKernel,
                         const detail::nd_range_base& ndRange,
                         const functorT& functor, int dimensions) {
    auto currentCommand = this->create_kernel_command_group(syclKernel);

    this->process_functor_arguments<kernelName, functorT>(functor, syclKernel,
                                                          currentCommand);

    this->execute_kernel_parallel_for_ptr(ndRange, syclKernel, functor,
                                          currentCommand, dimensions);
  }

  void parallel_for_impl(const detail::nd_range_base& ndRange,
                         kernel syclKernel,
                         detail::enqueue_device_kernel_command* currentCommand,
                         int dimensions);

  /** COMPUTECPP_DEV @endcond */

  /**
  @brief Parallel_for will enqueue the kernel @ref functor to be executed a
  number of
  instances working in parallel over the number of local and global work items
  specified
  by @ref ndRange.
  @tparam nameT The name of the kernel being enqueued
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @tparam dimensions Number of dimensions of the kernel
  @param ndRange Dimensions of the global and local work groups
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for(const nd_range<dimensions>& ndRange,
                    const functorT& functor) {
    parallel_for_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        functorT>(ndRange, functor, dimensions);
  }

  /**
  @brief Parallel_for will enqueue the kernel @ref functor to be executed a
  number of
  instances working in parallel over the number of local and global work items
  specified
  by @ref ndRange.
  @tparam nameT The name of the kernel being enqueued
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @tparam dimensions Number of dimensions of the kernel
  @param syclKernel The precompiled kernel to be enqueued
  @param ndRange Dimensions of the global and local work groups
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for(kernel syclKernel, const nd_range<dimensions>& ndRange,
                    const functorT& functor) {
    parallel_for_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        functorT>(syclKernel, ndRange, functor, dimensions);
  }

  /* @cond COMPUTECPP_DEV*/

  template <typename kernelName, typename functorT>
  void parallel_for_impl(kernel syclKernel, const detail::index_array& range,
                         const detail::index_array& globalOffset,
                         const functorT& functor, const int dimensions) {
    auto currentCommand = this->create_kernel_command_group(syclKernel);

    this->process_functor_arguments<kernelName, functorT>(functor, syclKernel,
                                                          currentCommand);

    detail::nd_range_base ndRange(range, globalOffset);

    this->execute_kernel_parallel_for_id_ptr(ndRange, syclKernel, functor,
                                             currentCommand, dimensions);
  }

  template <typename kernelName, typename functorT, int dimensions>
  void parallel_for_impl(const detail::index_array& range,
                         const detail::index_array& globalOffset,
                         functorT functor) {
    program p(
        program::create_program_for_kernel<kernelName>(this->get_context()));

    kernel syclKernel(p.get_kernel<kernelName>());

    auto currentCommand = this->create_kernel_command_group(syclKernel);

    this->process_functor_arguments<kernelName, functorT>(functor, syclKernel,
                                                          currentCommand);

    detail::nd_range_base ndRange(range, globalOffset);

    // We wrap the functor here so that generic lambdas
    // deduce to item correctly
    // The lambda has to be mutable to allow for different kinds of functors
    auto wrappedFunctor = [functor](detail::item_base& index) mutable {
      auto indexFinal = static_cast<item<dimensions, true>&>(index);
      functor(indexFinal);
    };
    this->execute_kernel_parallel_for_id_ptr(
        ndRange, syclKernel, wrappedFunctor, currentCommand, dimensions);
  }
  /* @endcond */
#if SYCL_LANGUAGE_VERSION >= 202002
  /**
  @brief This parallel_for will enqueue a kernel @ref functor to be executed a
  number of
  instances working in parallel over the number of global work items specified
  by @ref range with a variable number of @ref reduction objects also being
  passed.
  @tparam nameT The name of the kernel being enqueued
  @tparam dimensions Number of dimensions of the kernel
  @tparam restArgsTs Template parameter pack containing some number of reduction
  types followed by the functor type
  @param range Dimensions of the global work group
  @param restArgs Parameter pack containing some number of reduction objects
  followed by the kernel functor
  */
  template <typename nameT = std::nullptr_t, int dimensions,
            typename... restArgsTs>
  void parallel_for(const range<dimensions>& range, restArgsTs... restArgs) {
    auto restArgsTuple = std::make_tuple(std::move(restArgs)...);
    constexpr auto numRestArgs = sizeof...(restArgsTs);
    auto functor = std::move(std::get<numRestArgs - 1>(restArgsTuple));
    using functorT = decltype(functor);
    auto reductionTuple = detail::extract_reduction_impl<restArgsTs...>::get(
        std::move(restArgsTuple));

    auto reductionImpl = std::get<0>(reductionTuple);
    using reductionT = decltype(reductionImpl);
    size_t localMemBytesPerItem =
        !reductionT::hasAtomics ? sizeof(typename reductionT::data_t) : 0;
    auto reductionRange = detail::get_reduction_range(
        range,
        detail::reduction_get_max_wg_size(m_queue, localMemBytesPerItem));
    auto reductionKernel =
        detail::get_reduction_kernel<dimensions, functorT, reductionT>(
            *this, functor, reductionImpl, range, reductionRange);

    this->parallel_for_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        decltype(reductionKernel)>(reductionRange, reductionKernel, dimensions);
  }

#endif

  /**
  @brief Parallel_for will enqueue the kernel @ref functor to be executed a
  number of
  instances working in parallel over the number of global work items specified
  by @ref range.
  @tparam nameT The name of the kernel being enqueued
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @tparam dimensions Number of dimensions of the kernel
  @param range Dimensions of the global work group
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for(const range<dimensions>& range, const functorT& functor) {
    parallel_for_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        dimensions>(range, detail::index_array(0, 0, 0), functor);
  }

  /**
  @brief Parallel_for will enqueue the kernel @ref functor to be executed a
  number of
  instances working in parallel over the number of global work items specified
  by @ref range.
  @tparam nameT The name of the kernel being enqueued
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @param range Size of the global work group
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT>
  void parallel_for(const size_t range, const functorT& functor) {
    parallel_for_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        1>(detail::index_array(range, 1, 1), detail::index_array(0, 0, 0),
           functor);
  }

  /**
  @brief Parallel_for will enqueue the kernel @ref functor to be executed a
  number of
  instances working in parallel over the number of global work items specified
  by @ref range.
  @tparam nameT The name of the kernel being enqueued
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @tparam dimensions Number of dimensions of the kernel
  @param range Dimensions of the global work group
  @param offset The offset into the data being executed
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for(const range<dimensions>& range,
                    const id<dimensions>& offset, const functorT& functor) {
    parallel_for_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        dimensions>(range, offset, functor);
  }

  /**
  @brief Parallel_for will enqueue the precompiled kernel @ref syclKernel to be
  executed a number of
  instances working in parallel over the number of global work items specified
  by @ref range.
  @tparam nameT The name of the kernel being enqueued
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @tparam dimensions Number of dimensions of the kernel
  @param syclKernel The precompiled kernel which is being run
  @param range Dimensions of the global work group
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for(kernel syclKernel, const range<dimensions>& range,
                    const functorT& functor) {
    parallel_for_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        functorT>(syclKernel, range, detail::index_array(0, 0, 0), functor,
                  dimensions);
  }

  /**
  @brief Parallel_for will enqueue the precompiled kernel @ref syclKernel to be
  executed a number of
  instances working in parallel over the number of global work items specified
  by @ref range.
  @tparam nameT The name of the kernel being enqueued
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @tparam dimensions Number of dimensions of the kernel
  @param syclKernel The precompiled kernel which is being run
  @param range Dimensions of the global work group
  @param offset The offset into the data being executed
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for(kernel syclKernel, const range<dimensions>& range,
                    const id<dimensions>& offset, const functorT& functor) {
    parallel_for_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        functorT>(syclKernel, range, offset, functor, dimensions);
  }

  /////////////// API : Hierarchical

  /**
  @brief parallel_for_work_group will enqueue the precompiled kernel @ref
  syclKernel to
  be executed a number of instances working in parallel over the number of local
  and global work items specified by @ref numGroups.
  @tparam dimensions Number of dimensions of the kernel
  @param numGroups Dimensions of the global and local work groups
  @param syclKernel The precompiled kernel which is being run
  */
  template <int dimensions>
  void parallel_for_work_group(const range<dimensions>& numGroups,
                               kernel syclKernel) {
    this->parallel_for_work_group_impl(
        static_cast<const detail::index_array&>(numGroups), syclKernel,
        dimensions);
  }

  /** @cond COMPUTECPP_DEV*/

  void parallel_for_work_group_impl(const detail::index_array& numGroups,
                                    kernel syclKernel, int dimensions);

  // Explicitly disable the * version to avoid unreadable errors.
  template <int dimensions>
  void parallel_for_work_group(const range<dimensions>& numGroups,
                               kernel* syclKernel) = delete;

  // Explicitly disable the * version to avoid unreadable errors.
  template <int dimensions>
  void parallel_for_work_group(const range<dimensions>& numGroups,
                               const range<dimensions>& groupSize,
                               kernel* syclKernel) = delete;

  template <typename kernelName, typename functorT>
  void parallel_for_work_group_impl(const detail::index_array& numGroups,
                                    const detail::index_array& groupSize,
                                    const functorT& functor,
                                    const int dimensions) {
    detail::nd_range_base ndRange(numGroups * groupSize, groupSize,
                                  detail::index_array(0, 0, 0));
    program p(
        program::create_program_for_kernel<kernelName>(this->get_context()));

    kernel syclKernel(p.get_kernel<kernelName>());

    auto currentCommand = this->create_kernel_command_group(syclKernel);

    this->process_functor_arguments<kernelName, functorT>(functor, syclKernel,
                                                          currentCommand);

    this->execute_kernel_parallel_for_work_group_ptr(
        ndRange, syclKernel, functor, currentCommand, dimensions);
  }

  template <typename kernelName, typename functorT>
  void parallel_for_work_group_impl(kernel syclKernel,
                                    const detail::index_array& numGroups,
                                    const detail::index_array& groupSize,
                                    const functorT& functor,
                                    const int dimensions) {
    auto currentCommand = this->create_kernel_command_group(syclKernel);

    detail::nd_range_base ndRange(numGroups * groupSize, groupSize,
                                  detail::index_array(0, 0, 0));

    this->process_functor_arguments<kernelName, functorT>(functor, syclKernel,
                                                          currentCommand);

    this->execute_kernel_parallel_for_work_group_ptr(
        ndRange, syclKernel, functor, currentCommand, dimensions);
  }

  template <typename kernelName, typename functorT>
  void parallel_for_work_group_impl(const detail::index_array& numGroups,
                                    const functorT& functor,
                                    const int dimensions) {
    program p(
        program::create_program_for_kernel<kernelName>(this->get_context()));

    kernel syclKernel(p.get_kernel<kernelName>());

    auto currentCommand = this->create_kernel_command_group(syclKernel);

    detail::index_array groupSize = detail::index_array(1, 1, 1);
    detail::nd_range_base ndRange(numGroups * groupSize, groupSize,
                                  detail::index_array(0, 0, 0));

    this->process_functor_arguments<kernelName, functorT>(functor, syclKernel,
                                                          currentCommand);

    this->execute_kernel_parallel_for_work_group_ptr(
        ndRange, syclKernel, functor, currentCommand, dimensions);
  }

  template <typename kernelName, typename functorT>
  void parallel_for_work_group_impl(kernel syclKernel,
                                    const detail::index_array& numGroups,
                                    const functorT& functor,
                                    const int dimensions) {
    auto currentCommand = this->create_kernel_command_group(syclKernel);

    detail::index_array groupSize = detail::index_array(1, 1, 1);
    detail::nd_range_base ndRange(numGroups * groupSize, groupSize,
                                  detail::index_array(0, 0, 0));

    this->process_functor_arguments<kernelName, functorT>(functor, syclKernel,
                                                          currentCommand);

    this->execute_kernel_parallel_for_work_group_ptr(
        ndRange, syclKernel, functor, currentCommand, dimensions);
  }
  /* @endcond */

  /**
  @brief parallel_for_work_group will enqueue the precompiled kernel @ref
  syclKernel to
  be executed a number of instances working in parallel over the number of local
  and global
  work items specified by @ref range.
  @tparam nameT The name of the kernel being enqueued
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @tparam dimensions Number of dimensions of the kernel
  @param syclKernel The precompiled kernel which is being run
  @param range Dimensions of the global work groups
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for_work_group(kernel syclKernel,
                               const range<dimensions>& range,
                               const functorT& functor) {
    parallel_for_work_group_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        functorT>(syclKernel, range, functor, dimensions);
  }

  /**
  @brief parallel_for_work_group will enqueue the kernel @ref functor to
  be executed a number of instances working in parallel over the number of local
  and global
  work items specified by @ref range.
  @tparam nameT The name of the kernel being enqueued
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @tparam dimensions Number of dimensions of the kernel
  @param range Dimensions of the global and local work groups
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for_work_group(const range<dimensions>& range,
                               const functorT& functor) {
    parallel_for_work_group_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        functorT>(range, functor, dimensions);
  }

  /**
  @brief parallel_for_work_group will enqueue the precompiled kernel @ref
  syclKernel to
  be executed a number of instances working in parallel over the number of local
  and global
  work items specified by @ref numGroups and @ref groupSize.
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @tparam dimensions Number of dimensions of the kernel
  @param syclKernel The precompiled kernel which is being run
  @param numGroups dimensions of the work groups being launched
  @param groupSize each work group will launch work-items of dimension of
  groupSize  @tparam nameT The name of the kernel being enqueued
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for_work_group(const range<dimensions>& numGroups,
                               const range<dimensions>& groupSize,
                               const functorT& functor) {
    parallel_for_work_group_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        functorT>(numGroups, groupSize, functor, dimensions);
  }

  /**
  @brief parallel_for_work_group will enqueue the precompiled kernel @ref
  syclKernel to
  be executed a number of instances working in parallel over the number of local
  and global
  work items specified by @ref numGroups and @ref groupSize.
  @tparam nameT The name of the kernel being enqueued
  @tparam functorT This is the type of the kernel. It will be automatically
  deduced by the compiler
  @tparam dimensions Number of dimensions of the kernel
  @param syclKernel The precompiled kernel which is being run
  @param numGroups dimensions of the work groups being launched
  @param groupSize each work group will launch work-items of dimension of
  groupSize
  @param functor The kernel being enqueued
  */
  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for_work_group(kernel syclKernel,
                               const range<dimensions>& numGroups,
                               const range<dimensions>& groupSize,
                               const functorT& functor) {
    parallel_for_work_group_impl<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        functorT>(syclKernel, numGroups, groupSize, functor, dimensions);
  }

  /* @cond COMPUTECPP_DEV*/
  /** Gets the number of kernels in the current command group.
   */
  unsigned get_num_kernels() const;
  /* @endcond */

  /**
    @brief Function that registers a placeholder accessor with the handler.
    Defined in Codeplay Extension CP004.
    @param acc Placeholder accessor
  */
  template <typename elemT, int kDims, access::mode kMode,
            access::target kTarget>
  void require(const accessor<elemT, kDims, kMode, kTarget,
                              access::placeholder::true_t>& acc) {
    this->require(static_cast<const accessor_base&>(acc));
  }

  /** @brief Registers a global memory accessor for DMA transfer
   * @param acc Accessor to use in a DMA transfer
   * @param stride DMA transfer stride, in number of elements
   */
  template <typename elemT, int kDims, access::mode kMode,
            access::placeholder isPlaceholder>
  void register_for_dma(
      accessor<elemT, kDims, kMode, access::target::global_buffer,
               isPlaceholder>& acc,
      size_t stride) {
    this->register_for_dma(static_cast<accessor_base&>(acc),
                           stride * sizeof(elemT));
  }

  /** @brief Registers a constant memory accessor for DMA transfer
   * @param acc Accessor to use in a DMA transfer
   * @param stride DMA transfer stride, in number of elements
   */
  template <typename elemT, int kDims, access::placeholder isPlaceholder>
  void register_for_dma(
      accessor<elemT, kDims, access::mode::read, access::target::global_buffer,
               isPlaceholder>& acc,
      size_t stride) {
    this->register_for_dma(static_cast<accessor_base&>(acc),
                           stride * sizeof(elemT));
  }

  /**
    @brief Function that registers a placeholder accessor with the handler
    and the associated storage.
    Defined in Codeplay Extension CP004.
    Will fail if accessor already associated with storage.
    @param buf Buffer object
    @param acc Placeholder accessor
    @deprecated Bind the null accessor first, then call require()
  */
  template <typename elemT, int kDims, access::mode kMode,
            access::target kTarget>
  COMPUTECPP_DEPRECATED_API("Deprecated Codeplay extension function: "
                            "Bind the null accessor first, then call require()")
  void require(buffer<elemT, kDims>& bufObj,
               const accessor<elemT, kDims, kMode, kTarget,
                              access::placeholder::true_t>& acc) {
    this->require(static_cast<const accessor_base&>(acc), bufObj.get_impl(),
                  kMode, kTarget);
  }

  /**
    @brief Register a single event that this handler should wait for before
    running.
    @param e The event that the handler should wait for before running.
  */
  void experimental_depends_on(cl::sycl::event e);

  /** @brief Register a set of events that this handler should wait for before
  running.
   * @param v a vector of events.
   */
  void experimental_depends_on(const std::vector<cl::sycl::event>& v);

  /// @copydoc experimental_depends_on(cl::sycl::event)
  inline void depends_on(cl::sycl::event e) {
    this->experimental_depends_on(e);
  }

  /// @copydoc experimental_depends_on(const std::vector<cl::sycl::event>&)
  inline void depends_on(const std::vector<cl::sycl::event>& v) {
    this->experimental_depends_on(v);
  }

  /////////////// API : Copy from/to/in device

  /**
    @brief Copies the data from the device accessor to the host pointer.
           hostPtr must have enough space allocated to match the size of the
           accessor data.

           The underlying type of the accessor and the host pointer must match
           - Accessor type can be const
           - At least one type is allowed to be void
    @tparam TAcc Underlying type of the data associated with the accessor
    @tparam THostPtr Underlying type of the host pointer data
    @tparam dims Number of dimensions of the accessor
    @tparam accessMode Access mode of the accessor
    @tparam accessTarget Access target of the accessor
    @tparam isPlaceholder Whether the accessor is a placeholder
    @tparam COMPUTECPP_ENABLE_IF The function is only valid when the access mode
            includes read access
    @param acc Accessor that is used to access the buffer or image
    @param hostPtr Host pointer that will be updated
  */
  template <typename TAcc, typename THostPtr, int dims,
            cl::sycl::access::mode accessMode,
            cl::sycl::access::target accessTarget,
            access::placeholder isPlaceholder,
            COMPUTECPP_ENABLE_IF(
                TAcc, (detail::can_copy_types<TAcc, THostPtr>::value &&
                       detail::is_read_mode<accessMode>::value))>
  void copy(accessor<TAcc, dims, accessMode, accessTarget, isPlaceholder> acc,
            shared_ptr_class<THostPtr> hostPtr) {
    auto&& hostPtrVoid = std::static_pointer_cast<void>(hostPtr);
    this->update_device_data(acc, hostPtrVoid, cl::sycl::access::mode::read,
                             true);
  }

  /**
    @brief Copies the data from the host pointer to the device accessor.
           hostPtr must have enough space allocated to match the size of the
           accessor data.

           The underlying type of the host pointer and the accessor must match
           - Host pointer type can be const
           - At least one type is allowed to be void
    @tparam THostPtr Underlying type of the host pointer data
    @tparam TAcc Underlying type of the data associated with the accessor
    @tparam dims Number of dimensions of the accessor
    @tparam accessMode Access mode of the accessor
    @tparam accessTarget Access target of the accessor
    @tparam isPlaceholder Whether the accessor is a placeholder
    @tparam COMPUTECPP_ENABLE_IF The function is only valid when the access mode
            includes write access
    @param hostPtr Host pointer that points to the new data
    @param acc Accessor that is used to access the buffer or image
  */
  template <typename TAcc, typename THostPtr, int dims,
            cl::sycl::access::mode accessMode,
            cl::sycl::access::target accessTarget,
            access::placeholder isPlaceholder,
            COMPUTECPP_ENABLE_IF(
                TAcc, (detail::can_copy_types<THostPtr, TAcc>::value &&
                       detail::is_write_mode<accessMode>::value))>
  void copy(shared_ptr_class<THostPtr> hostPtr,
            accessor<TAcc, dims, accessMode, accessTarget, isPlaceholder> acc) {
    auto&& hostPtrVoid = std::static_pointer_cast<void>(
        std::const_pointer_cast<typename std::remove_const<THostPtr>::type>(
            hostPtr));
    this->update_device_data(acc, hostPtrVoid, cl::sycl::access::mode::write,
                             true);
  }

  /**
    @brief Copies the data from the device accessor to the host pointer.
           hostPtr must have enough space allocated to match the size of the
           accessor data.

           The underlying type of the accessor and the host pointer must match
           - Accessor type can be const
           - At least one type is allowed to be void
    @tparam TAcc Underlying type of the data associated with the accessor
    @tparam THostPtr Underlying type of the host pointer data
    @tparam dims Number of dimensions of the accessor
    @tparam accessMode Access mode of the accessor
    @tparam accessTarget Access target of the accessor
    @tparam isPlaceholder Whether the accessor is a placeholder
    @tparam COMPUTECPP_ENABLE_IF The function is only valid when the access mode
            includes read access
    @param acc Accessor that is used to access the buffer or image
    @param hostPtr Host pointer that will be updated
  */
  template <typename TAcc, typename THostPtr, int dims,
            cl::sycl::access::mode accessMode,
            cl::sycl::access::target accessTarget,
            access::placeholder isPlaceholder,
            COMPUTECPP_ENABLE_IF(
                TAcc, (detail::can_copy_types<TAcc, THostPtr>::value &&
                       detail::is_read_mode<accessMode>::value))>
  void copy(accessor<TAcc, dims, accessMode, accessTarget, isPlaceholder> acc,
            THostPtr* hostPtr) {
    auto hostPtrVoid = shared_ptr_class<void>(static_cast<void*>(hostPtr),
                                              detail::NullDeleter());
    this->update_device_data(acc, hostPtrVoid, cl::sycl::access::mode::read,
                             true);
  }

  /**
    @brief Copies the data from the host pointer to the device accessor.
           hostPtr must have enough space allocated to match the size of the
           accessor data.

           The underlying type of the host pointer and the accessor must match
           - Host pointer type can be const
           - At least one type is allowed to be void
    @tparam THostPtr Underlying type of the host pointer data
    @tparam TAcc Underlying type of the data associated with the accessor
    @tparam dims Number of dimensions of the accessor
    @tparam accessMode Access mode of the accessor
    @tparam accessTarget Access target of the accessor
    @tparam isPlaceholder Whether the accessor is a placeholder
    @tparam COMPUTECPP_ENABLE_IF The function is only valid when the access mode
            includes write access
    @param hostPtr Host pointer that points to the new data
    @param acc Accessor that is used to access the buffer or image
  */
  template <typename TAcc, typename THostPtr, int dims,
            cl::sycl::access::mode accessMode,
            cl::sycl::access::target accessTarget,
            access::placeholder isPlaceholder,
            COMPUTECPP_ENABLE_IF(
                TAcc, (detail::can_copy_types<THostPtr, TAcc>::value &&
                       detail::is_write_mode<accessMode>::value))>
  void copy(const THostPtr* hostPtr,
            accessor<TAcc, dims, accessMode, accessTarget, isPlaceholder> acc) {
    auto hostPtrVoid = shared_ptr_class<void>(
        static_cast<void*>(const_cast<THostPtr*>(hostPtr)),
        detail::NullDeleter());
    this->update_device_data(acc, hostPtrVoid, cl::sycl::access::mode::write,
                             true);
  }

  /**
    @brief Copies data associated with the origin accessor to the data
           associated with the destination accessor.

           There are a few restrictions on the accessors:
           - The underlying type and number of dimensions must match
             - Origin type can be const
           - The origin accessor access mode must include read access
           - The destination accessor access mode must include write access
           - The size of the destination accessor data must be enough to hold
             the data from the origin accessor
    @tparam T Underlying type of the data associated with the origin
            accessor
    @tparam U Underlying type of the data associated with the destination
            accessors
    @tparam dimsOrig Number of dimensions of the origin accessor
    @tparam dimsDest Number of dimensions of the destination accessor
    @tparam accModeOrig Access mode of the origin accessor
    @tparam accModeDest Access mode of the destination accessor
    @tparam accTargetOrig Access target of the origin accessor
    @tparam accTargetDest Access target of the destination accessor
    @tparam isPlaceholder Whether the origin accessor is a placeholder
    @tparam isPlaceholder Whether the destination accessor is a placeholder
    @tparam COMPUTECPP_ENABLE_IF Checks that the accessor types conform to the
            restrictions.
    @param originAcc Accessor with the data that will be copied from
    @param destinationAcc Accessor with the data that will be copied to
  */
  template <typename T, typename U, int dimsOrig, int dimsDest,
            access::mode accModeOrig, access::mode accModeDest,
            access::target accTargetOrig, access::target accTargetDest,
            access::placeholder isPlaceholderOrig,
            access::placeholder isPlaceholderDest,
            COMPUTECPP_ENABLE_IF(T,
                                 ((detail::can_copy_types<T, U>::value) &&
                                  (detail::is_read_mode<accModeOrig>::value) &&
                                  (detail::is_write_mode<accModeDest>::value)))>
  void copy(accessor<T, dimsOrig, accModeOrig, accTargetOrig, isPlaceholderOrig>
                originAcc,
            accessor<U, dimsDest, accModeDest, accTargetDest, isPlaceholderDest>
                destinationAcc) {
    this->copy_in_device(originAcc, destinationAcc);
  }

  /**
    @brief Fills the data associated with the accessor using the scalar value.

           Special case of copy from host to device where the origin is a scalar
           value that will be replicated across the range of the accessor.
    @tparam TAcc Underlying type of the data associated with the accessor
    @tparam T Underlying type of the host scalar
    @tparam dims Number of dimensions of the accessor
    @tparam accessMode Access mode of the accessor
    @tparam accessTarget Access target of the accessor
    @tparam isPlaceholder Whether the accessor is a placeholder
    @tparam COMPUTECPP_ENABLE_IF The function is only valid when the access mode
            includes read access
    @param acc Accessor with the data that will be filled
    @param val Scalar used to fill the device data with
  */
  template <
      typename TAcc, typename T, int dims, cl::sycl::access::mode accessMode,
      cl::sycl::access::target accessTarget, access::placeholder isPlaceholder,
      COMPUTECPP_ENABLE_IF(TAcc, (detail::can_copy_types<T, TAcc>::value &&
                                  detail::is_write_mode<accessMode>::value))>
  void fill(accessor<TAcc, dims, accessMode, accessTarget, isPlaceholder> acc,
            T val) {
    static_assert(((sizeof(T) == 1) || (sizeof(T) == 2) || (sizeof(T) == 4) ||
                   (sizeof(T) == 8) || (sizeof(T) == 16) || (sizeof(T) == 32) ||
                   (sizeof(T) == 64) || (sizeof(T) == 128)),
                  "The size of the scalar type can only be one of "
                  "{1, 2, 4, 8, 16, 32, 64, 128}");
    this->fill(acc, static_cast<const void*>(&val), sizeof(T));
  }

  /** @brief Updates the device data with the current host accessor
   * @param AccessorT accessor
   */
  template <typename T, int dims, cl::sycl::access::mode accessMode,
            cl::sycl::access::target accessTarget,
            access::placeholder isPlaceholder>
  void update_host(
      accessor<T, dims, accessMode, accessTarget, isPlaceholder> acc) {
    update_device_data(acc, nullptr, cl::sycl::access::mode::write, false);
  }

  /**
   * @brief Fills the memory pointed by @p ptr.
   * @tparam T The type of the element.
   * @param ptr Pointer object to fill.
   * @param pattern The pattern to fill each element of @p ptr
   * @param count The number of elements of type T to fill.
   */
  template <typename T>
  void fill(void* ptr, const T& pattern, size_t count) {
#if (defined(COMPUTECPP_WINDOWS) || !defined(COMPUTECPP_GCC_PRE_5)) &&         \
    !defined(__SYCL_DEVICE_ONLY__)
    static_assert(std::is_trivially_copyable<T>::value,
                  "Type T needs to be trivially copyable");
#endif
    fill(ptr, static_cast<const void*>(&pattern), sizeof(T), count * sizeof(T));
  }

#if SYCL_LANGUAGE_VERSION >= 202002
  /** Sets the numBytes from memory pointed at by @p ptr to given value
   * interpreted as an unsigned char.
   * @param ptr Pointer to the memory location to write to.
   * @param value The value to set memory to. static_cast to unsigned char.
   * @param numBytes The number of bytes to set from ptr
   */
  inline void memset(void* ptr, int value, size_t numBytes) {
    memset_impl(ptr, value, numBytes);
  }
#endif  // SYCL_LANGUAGE_VERSION >= 202002

  /**
   * @brief Copies @p count bytes from @p src to @dest.
   * @param dest Pointer to the memory location to copy to.
   * @param src Pointer to the memory location to copy from.
   * @param size The number of bytes to copy.
   */
  void memcpy(void* dest, const void* src, size_t size);

  /////////////// API: Performance hints

  /**
   * @brief Hints to the SYCL runtime that the data is available earlier
   *        than when the USM model would require it.
   *        Can only be overlapped with kernel execution
   *        when Concurrent or System USM is available.
   * @param ptr Pointer to the memory to be prefetched to the device
   * @param size Number of bytes requested to be prefetched
   */
  void experimental_prefetch(const void* ptr, size_t size);

  /// @copydoc experimental_prefetch(const void*, size_t)
  inline void prefetch(const void* ptr, size_t size) {
    this->experimental_prefetch(ptr, size);
  }

  /////////////// API: Host task

#if SYCL_LANGUAGE_VERSION >= 202002

  /** Schedules work that executes on the host, as part of the scheduler DAG
   * @tparam T Type of the callable to execute
   * @param hostTaskCallable Callable object that will be executed
   */
  template <typename T>
  void host_task(T&& hostTaskCallable) {
    if constexpr (std::is_invocable_v<T, interop_handle>) {
      this->interop_task_impl(std::forward<T>(hostTaskCallable));
    } else {
      this->interop_task_impl([callable = std::forward<T>(hostTaskCallable)](
                                  const interop_handle&) { callable(); });
    }
  }

#endif  // SYCL_LANGUAGE_VERSION >= 202002

 protected:
  /**
    @brief Updates device data by copying to/from the device
    @param acc Accessor that is used to access the buffer or image
    @param hostPtr Pointer that points to data on the host
    @param accessMode Operation indicator
                      (read -> copy_from_device, write -> copy_to_device)
    @param userProvidedPtr Indicated whether the host pointer was provided by
    the user or whether to use the internal one
  */
  void update_device_data(const accessor_base& acc,
                          shared_ptr_class<void> hostPtr,
                          cl::sycl::access::mode accessMode,
                          bool userProvidedPtr);

  /**
    @brief Copies data associated with the origin accessor to the data
           associated with the destination accessor.
    @param originAcc Accessor with the data that will be copied from
    @param destinationAcc Accessor with the data that will be copied to
  */
  void copy_in_device(const accessor_base& originAcc,
                      const accessor_base& destinationAcc);

  /**
    @brief Fills the range of the accessor with value of \ref{hostScalarPtr[0]}
    @param acc Accessor with the data that will be filled
    @param patternData Host data used to fill the device data with
    @param patternSize Size of the host data
  */
  void fill(const accessor_base& acc, const void* patternData,
            const size_t patternSize);

  /**
   * @brief Fills the memory pointed by @p ptr.
   * @param ptr Pointer object to fill.
   * @param patternData Pointer to the memory that contains the pattern to use
   * when filling @p ptr.
   * @param patternSize The size in bytes of the pattern.
   * @param size The number of bytes of @p ptr to fill with @p patternData.
   */
  void fill(void* ptr, const void* patternData, size_t patternSize,
            size_t size);

 protected:
  /** Schedules a host task with an interop_handle object
   * @param hostTaskCallable Callable object that will be executed
   */
  void interop_task_impl(const detail::interop_task_ptr& hostTaskCallable);

 protected:
  /** Creates a handler for an specific queue.
   */
  explicit handler(const dqueue_shptr& q,
                   const dqueue_shptr& fallbackQueue = nullptr);

  /** Returns the current context for the command group.
   */
  context get_context() const;

  /** Returns the current device for the command group.
   */
  ddevice_wkptr get_device_weak() const;

  /** Creates the internal structures to execute the kernel.
   * This function is explicitly instantiated on the cpp file for
   * those FunctorPtr types supported.
   *
   * @param nd_range_base The given nd range
   * @param syclKernel The SYCL device kernel
   * @param FunctorPtr  The std::function pointer to the user functor
   * @param currentCommand  The command currently being executing
   */
  void execute_kernel_single_task_ptr(
      const detail::nd_range_base& ndRange, const kernel& syclKernel,
      const detail::single_task_ptr& funcPtr,
      detail::enqueue_device_kernel_command* currentCommand);
  void execute_kernel_parallel_for_ptr(
      const detail::nd_range_base& ndRange, const kernel& syclKernel,
      const detail::parallel_for_ptr& funcPtr,
      detail::enqueue_device_kernel_command* currentCommand, int dimensions);
  void execute_kernel_parallel_for_id_ptr(
      const detail::nd_range_base& ndRange, const kernel& syclKernel,
      const detail::parallel_for_id_ptr& funcPtr,
      detail::enqueue_device_kernel_command* currentCommand, int dimensions);
  void execute_kernel_parallel_for_work_group_ptr(
      const detail::nd_range_base& ndRange, const kernel& syclKernel,
      const detail::parallel_for_work_group_ptr& funcPtr,
      detail::enqueue_device_kernel_command* currentCommand, int dimensions);

  /** Gets the parameters from a functor and sets them as OpenCL arguments.
   * Internal implementation.
   * @param syclKernel Kernel to which the functor is associated
   * @param functorBuffer Functor buffer casted down to a binary array
   * @param SI Kernel struct iterator
   * @param SE Kernel struct iterator
   * @param OI Kernel struct iterator
   */
  void process_functor_arguments_impl(
      kernel syclKernel, detail::binary_address functorBuffer,
      const detail::functor_arg_descriptor& argDesc,
      detail::enqueue_device_kernel_command* currentCommand);

  /**
    @brief Internal function that registers a placeholder accessor with the
           handler
    @param acc Placeholder accessor
  */
  void require(const accessor_base& acc);

  /**
    @brief Internal function that registers a placeholder accessor with the
           handler
    @param acc Placeholder accessor
    @deprecated Bind the null accessor first, then call require()
  */
  void require(const accessor_base& acc, dmem_shptr memObj, access::mode mode,
               access::target target);

  /** @brief Registers an accessor for DMA transfer
   * @param acc Accessor to use in a DMA transfer
   * @param stride DMA transfer stride, in bytes
   */
  void register_for_dma(accessor_base& acc, size_t strideBytes);

  /** @brief Creates a kernel command group
   * Internal implementation.
   * @return Pointer to the newly created command
   */
  detail::enqueue_device_kernel_command* create_kernel_command_group(
      kernel& syclKernel);

  /** Gets the optimal workgroup size for the current device and the given
   * kernel.
   * Internal implementation.
   * @param syclKernel Kernel to which we need to compute the workgroup size.
   */
  detail::index_array get_optimal_workgroup_size(const kernel& syclKernel);

  /** Internal transaction associated with the handler
   */
  dtrans_uptr m_trans;

  /** Queue to which this handler was submitted to
   */
  dqueue_shptr m_queue;

  /** @brief Pointer to the fallback queue (if any)
   */
  dqueue_shptr m_fallbackQueue;

  /* m_paramVec.
   * List of parameters to add to a kernel in
   * interop mode
   */
  vector_class<add_param_func_t> m_paramVec;

  /** Number of kernels in the command group.
   */
  unsigned m_numKernels;
};

/** @brief inner loop of parallel_for_work_group, the Hierarchical API.
 * @deprecated Use group::parallel_for_work_item instead
 */
template <typename functorT, int dimensions>
COMPUTECPP_DEPRECATED_BY_SYCL_VER(201703,
                                  "Use group::parallel_for_work_item instead.")
void parallel_for_work_item(group<dimensions> groupID,
                            const functorT& functor) {
  group<dimensions>(groupID).parallel_for_work_item(functor);
}

/** @brief inner loop of parallel_for_work_group with a logical local range, the
 * Hierarchical API.
 * @deprecated Use group::parallel_for_work_item instead
 */
template <typename functorT, int dimensions>
COMPUTECPP_DEPRECATED_BY_SYCL_VER(201703,
                                  "Use group::parallel_for_work_item instead.")
void parallel_for_work_item(group<dimensions> groupID,
                            range<dimensions> localRange,
                            const functorT& functor) {
  group<dimensions>(groupID).parallel_for_work_item(localRange, functor);
}

namespace detail {

/** @brief Helper struct for calling handler::set_args for an OpenCL kernel
 * @tparam CurrentT Type of the current parameter
 * @tparam Ts Types of subsequent parameters
 */
template <typename CurrentT, typename... Ts>
struct set_args_helper<CurrentT, Ts...> {
  /** @brief Helper function for calling handler::set_args for an OpenCL kernel
   * @param cgh Command group handler
   * @param index Index of the current parameter
   * @param current Value of the current parameter
   * @param args Values of subsequent parameters
   */
  static void apply(handler& cgh, int index, CurrentT&& current, Ts&&... args) {
    cgh.set_arg(index, current);
    set_args_helper<Ts...>::apply(cgh, (index + 1), std::forward<Ts>(args)...);
  }
};

/** @brief Specialization of the helper struct for calling handler::set_args
 *        for an OpenCL kernel for a single parameter
 * @tparam T Type of the parameter
 */
template <typename T>
struct set_args_helper<T> {
  /** @brief Helper function for calling handler::set_args with one parameter
   *        for an OpenCL kernel
   * @param cgh Command group handler
   * @param index Index of the parameter
   * @param arg Value of the parameter
   */
  static void apply(handler& cgh, int index, T&& arg) {
    cgh.set_arg(index, std::forward<T>(arg));
  }
};

/** @brief Nullary specialization for set_args_helper
 */
template <>
struct set_args_helper<> {
  static void apply(handler&, int) noexcept {}
};

}  // namespace detail

}  // namespace sycl
}  // namespace cl

#endif  // __SYCL_DEVICE_ONLY__

#ifdef __SYCL_DEVICE_ONLY__

namespace cl {
namespace sycl {

class handler {
 public:
  explicit handler(dqueue_shptr) {}

  //////////////// Set arg mechanism
  template <typename T>
  void set_arg(int /*paramNum*/, T /*param*/) {
    COMPUTECPP_CL_ERROR_CODE_MSG(
        CL_SUCCESS, detail::cpp_error_code::NOT_SUPPORTED_ERROR, nullptr,
        "Handler interoperability is not supported.");
  }
  template <typename... Ts>
  void set_args(Ts&&... /*args*/) {
    COMPUTECPP_CL_ERROR_CODE_MSG(
        CL_SUCCESS, detail::cpp_error_code::NOT_SUPPORTED_ERROR, nullptr,
        "Handler interoperability is not supported.");
  }

  /* The version of API that takes a kernel * has to be explicitly
   * deleted, otherwise it will get through the template enable_if and
   * cause a massive template error problem.
   */
  void single_task(kernel* syclKernel) = delete;
  template <int dimensions>
  void parallel_for(const nd_range<dimensions>& ndRange,
                    kernel* syclKernel) = delete;
  template <int dimensions>
  void parallel_for(const range<dimensions>& range,
                    kernel* syclKernel) = delete;
  template <int dimensions>
  void parallel_for(const range<dimensions>& range,
                    const id<dimensions>& offset, kernel* syclKernel) = delete;
  template <int dimensions>
  void parallel_work_group(const range<dimensions>& ndRange,
                           kernel* syclKernel) = delete;

  // Nothing to be done on the device side
  void single_task(kernel) {}

  // Nothing to be done on the device side
  template <int dimensions>
  void parallel_for(const nd_range<dimensions>&, kernel) {}

  // Nothing to be done on the device side
  template <int dimensions>
  void parallel_for(const range<dimensions>&, kernel) {}

  // Nothing to be done on the device side
  template <int dimensions>
  void parallel_for(const range<dimensions>&, const id<dimensions>&, kernel) {}

  // Nothing to be done on the device side
  template <int dimensions>
  void parallel_work_group(const range<dimensions>&, kernel) {}

  template <typename nameT = std::nullptr_t, typename functorT>
  void single_task(const functorT& functor) {
    detail::kernelgen_single_task<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        functorT>(functor);
  }

  template <typename nameT = std::nullptr_t, typename functorT>
  void single_task(kernel, const functorT& functor) {
    detail::kernelgen_single_task<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        functorT>(functor);
  }

  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for(kernel, const nd_range<dimensions>&,
                    const functorT& functor) {
    detail::kernelgen_parallel_for_nd<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        dimensions>(functor);
  }

  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for(const nd_range<dimensions>&, const functorT& functor) {
    // NOT ACTUALLY CALLED ONLY HERE TO CALL THE KERNEL GEN FUNCTION
    detail::kernelgen_parallel_for_nd<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        dimensions>(functor);
  }

  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for(kernel, const range<dimensions>&, const functorT& functor) {
    detail::kernelgen_parallel_for_id<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        dimensions>(functor);
  }

  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for(kernel, const range<dimensions>&, const id<dimensions>&,
                    const functorT& functor) {
    detail::kernelgen_parallel_for_id<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        dimensions>(functor);
  }

#if SYCL_LANGUAGE_VERSION >= 202002
  template <typename nameT = std::nullptr_t, int dimensions,
            typename... restArgsTs>
  void parallel_for(const range<dimensions>& range, restArgsTs... restArgs) {
    // NOT ACTUALLY CALLED ONLY HERE TO CALL THE KERNEL GEN FUNCTION
    auto restArgsTuple = std::make_tuple(std::move(restArgs)...);
    constexpr auto numRestArgs = sizeof...(restArgsTs);
    auto functor = std::move(std::get<numRestArgs - 1>(restArgsTuple));
    using functorT = decltype(functor);
    auto reductionTuple = detail::extract_reduction_impl<restArgsTs...>::get(
        std::move(restArgsTuple));
    auto reductionImpl = std::get<0>(reductionTuple);
    // Not actually used on the device but get_reduction_kernel requires a range
    // to be passed.
    auto reductionRange =
        nd_range<dimensions>(range<dimensions>(1), range<dimensions>(1));

    auto reductionKernel = detail::get_reduction_kernel(
        *this, functor, reductionImpl, range, reductionRange);
    detail::kernelgen_parallel_for_nd<
        typename detail::enable_functor<functorT, nameT>::kernel_name,
        decltype(reductionKernel), dimensions>(reductionKernel);
  }
#endif

  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for(const range<dimensions>&, const functorT& functor) {
    // NOT ACTUALLY CALLED ONLY HERE TO CALL THE KERNEL GEN FUNCTION
    detail::kernelgen_parallel_for_id<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        dimensions>(functor);
  }

  template <typename nameT = std::nullptr_t, typename functorT>
  void parallel_for(const size_t, const functorT& functor) {
    // NOT ACTUALLY CALLED ONLY HERE TO CALL THE KERNEL GEN FUNCTION
    detail::kernelgen_parallel_for_id<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        1>(functor);
  }

  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for(const range<dimensions>&, const id<dimensions>&,
                    const functorT& functor) {
    // NOT ACTUALLY CALLED ONLY HERE TO CALL THE KERNEL GEN FUNCTION
    detail::kernelgen_parallel_for_id<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        dimensions>(functor);
  }

  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for_work_group(kernel, const range<dimensions>&,
                               const functorT& functor) {
    // NOT ACTUALLY CALLED ONLY HERE TO CALL THE KERNEL GEN FUNCTION
    detail::kernelgen_parallel_for_work_group<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        dimensions>(functor);
  }

  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for_work_group(const range<dimensions>&,
                               const functorT& functor) {
    // NOT ACTUALLY CALLED ONLY HERE TO CALL THE KERNEL GEN FUNCTION
    detail::kernelgen_parallel_for_work_group<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        dimensions>(functor);
  }

  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for_work_group(kernel, const range<dimensions>&,
                               const range<dimensions>&,
                               const functorT& functor) {
    // NOT ACTUALLY CALLED ONLY HERE TO CALL THE KERNEL GEN FUNCTION
    detail::kernelgen_parallel_for_work_group<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        dimensions>(functor);
  }

  template <typename nameT = std::nullptr_t, typename functorT, int dimensions>
  void parallel_for_work_group(const range<dimensions>&,
                               const range<dimensions>&,
                               const functorT& functor) {
    // NOT ACTUALLY CALLED ONLY HERE TO CALL THE KERNEL GEN FUNCTION
    detail::kernelgen_parallel_for_work_group<
        typename detail::enable_functor<functorT, nameT>::kernel_name, functorT,
        dimensions>(functor);
  }

  template <typename elemT, int kDims, access::mode kMode,
            access::target kTarget>
  void require(const accessor<elemT, kDims, kMode, kTarget,
                              access::placeholder::true_t>&) {
    // NOT ACTUALLY CALLED
  }

  template <typename elemT, int kDims, access::mode kMode,
            access::target kTarget>
  void require(buffer<elemT, kDims>&,
               const accessor<elemT, kDims, kMode, kTarget,
                              access::placeholder::true_t>&) {
    // NOT ACTUALLY CALLED
  }

  void experimental_depends_on(cl::sycl::event) {
    // NOT ACTUALLY CALLED
  }

  void experimental_depends_on(const std::vector<cl::sycl::event>&) {
    // NOT ACTUALLY CALLED
  }

  inline void depends_on(cl::sycl::event e) {
    this->experimental_depends_on(e);
  }

  inline void depends_on(const std::vector<cl::sycl::event>& v) {
    this->experimental_depends_on(v);
  }

  template <typename elemT, int kDims, access::mode kMode,
            access::target kTarget, access::placeholder isPlaceholder>
  void register_for_dma(
      accessor<elemT, kDims, kMode, kTarget, isPlaceholder>& acc,
      size_t stride);

  /////////////// API : Copy from/to/in device

  template <typename TAcc, typename THostPtr, int dims,
            cl::sycl::access::mode accessMode,
            cl::sycl::access::target accessTarget,
            access::placeholder isPlaceholder,
            COMPUTECPP_ENABLE_IF(
                TAcc, (detail::can_copy_types<TAcc, THostPtr>::value &&
                       detail::is_read_mode<accessMode>::value))>
  void copy(accessor<TAcc, dims, accessMode, accessTarget, isPlaceholder>,
            shared_ptr_class<THostPtr>) {
    // No work for the device compiler
  }
  template <typename TAcc, typename THostPtr, int dims,
            cl::sycl::access::mode accessMode,
            cl::sycl::access::target accessTarget,
            access::placeholder isPlaceholder,
            COMPUTECPP_ENABLE_IF(
                TAcc, (detail::can_copy_types<THostPtr, TAcc>::value &&
                       detail::is_write_mode<accessMode>::value))>
  void copy(shared_ptr_class<THostPtr>,
            accessor<TAcc, dims, accessMode, accessTarget, isPlaceholder>) {
    // No work for the device compiler
  }
  template <typename TAcc, typename THostPtr, int dims,
            cl::sycl::access::mode accessMode,
            cl::sycl::access::target accessTarget,
            access::placeholder isPlaceholder,
            COMPUTECPP_ENABLE_IF(
                TAcc, (detail::can_copy_types<TAcc, THostPtr>::value &&
                       detail::is_read_mode<accessMode>::value))>
  void copy(accessor<TAcc, dims, accessMode, accessTarget, isPlaceholder>,
            THostPtr*) {
    // No work for the device compiler
  }
  template <typename TAcc, typename THostPtr, int dims,
            cl::sycl::access::mode accessMode,
            cl::sycl::access::target accessTarget,
            access::placeholder isPlaceholder,
            COMPUTECPP_ENABLE_IF(
                TAcc, (detail::can_copy_types<THostPtr, TAcc>::value &&
                       detail::is_write_mode<accessMode>::value))>
  void copy(THostPtr*,
            accessor<TAcc, dims, accessMode, accessTarget, isPlaceholder>) {
    // No work for the device compiler
  }
  template <typename T, typename U, int dimsOrig, int dimsDest,
            access::mode accModeOrig, access::mode accModeDest,
            access::target accTargetOrig, access::target accTargetDest,
            access::placeholder isPlaceholderOrig,
            access::placeholder isPlaceholderDest,
            COMPUTECPP_ENABLE_IF(T,
                                 ((detail::can_copy_types<T, U>::value) &&
                                  (detail::is_read_mode<accModeOrig>::value) &&
                                  (detail::is_write_mode<accModeDest>::value)))>
  void copy(
      accessor<T, dimsOrig, accModeOrig, accTargetOrig, isPlaceholderOrig>,
      accessor<U, dimsDest, accModeDest, accTargetDest, isPlaceholderDest>) {
    // No work for the device compiler
  }
  template <
      typename TAcc, typename T, int dims, cl::sycl::access::mode accessMode,
      cl::sycl::access::target accessTarget, access::placeholder isPlaceholder,
      COMPUTECPP_ENABLE_IF(TAcc, (detail::can_copy_types<T, TAcc>::value &&
                                  detail::is_write_mode<accessMode>::value))>
  void fill(accessor<TAcc, dims, accessMode, accessTarget, isPlaceholder>, T) {
    // No work for the device compiler
  }

  template <typename T, int dims, cl::sycl::access::mode accessMode,
            cl::sycl::access::target accessTarget,
            access::placeholder isPlaceholder>
  void update_host(accessor<T, dims, accessMode, accessTarget, isPlaceholder>) {
    // No work for the device compiler
  }

  template <typename T>
  void fill(void* /*ptr*/, const T& /*pattern*/, size_t /*count*/) {
    // No work for the device compiler
  }

#if SYCL_LANGUAGE_VERSION >= 202002
  void memset(void* /*ptr*/, int /*value*/, size_t /*numBytes*/) {
    // No work for the device compiler
  }
#endif  // SYCL_LANGUAGE_VERSION >= 202002

  void memcpy(void* /*dest*/, const void* /*src*/, size_t /*size*/) {
    // No work for the device compiler
  }

  /////////////// API: Performance hints

  void experimental_prefetch(const void* /*ptr*/, size_t /*size*/) {
    // No work for the device compiler
  }

  inline void prefetch(const void* /*ptr*/, size_t /*size*/) {
    // No work for the device compiler
  }

  /////////////// API: Host task

#if SYCL_LANGUAGE_VERSION >= 202002

  template <typename T>
  void host_task(T&& /*hostTaskCallable*/) {
    // No work for the device compiler
  }

#endif  // SYCL_LANGUAGE_VERSION >= 202002
};

template <typename functorT, int dimensions>
COMPUTECPP_DEPRECATED_BY_SYCL_VER(201703,
                                  "Use group::parallel_for_work_item instead.")
void parallel_for_work_item(group<dimensions> groupID,
                            const functorT& functor) {
  // NOT ACTUALLY CALLED ONLY HERE TO CALL THE KERNEL GEN FUNCTION
  detail::kernelgen_parallel_for_work_item<dimensions, functorT>(groupID,
                                                                 functor);
}

template <typename functorT, int dimensions>
COMPUTECPP_DEPRECATED_BY_SYCL_VER(201703,
                                  "Use group::parallel_for_work_item instead.")
void parallel_for_work_item(group<dimensions> groupID,
                            range<dimensions> localRange,
                            const functorT& functor) {
  // NOT ACTUALLY CALLED ONLY HERE TO CALL THE KERNEL GEN FUNCTION
  detail::kernelgen_parallel_for_work_item<dimensions, functorT>(
      groupID, localRange, functor);
}

}  // namespace sycl
}  // namespace cl

#endif  // __SYCL_DEVICE_ONLY__

#endif  // RUNTIME_INCLUDE_SYCL_APIS_H_
