
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<style>html, body {
    background-color: #ccc;
    margin: 0;
    padding: 0;
    font-family: 'Open Sans', arial, sans-serif;
}

a {
    color: inherit;
    text-decoration: inherit;
    cursor: pointer
}

h1, h2, h3, h4, h5, h6 {
    cursor: inherit !important;
}

* {
    box-sizing: border-box;
}

main {
    background-color: white;
    padding: 2rem 4rem 2rem 4rem;
}

@media screen and (min-width: 56rem) {
    html, body {
        height: 100%;
    }

    main {
        box-shadow: 10px 0px 10px -8px rgba(0,0,0,0.1);
    }

    .combined-document main {
        margin: 0 0 0 320px;
        max-width: 1000px;
        min-height: 100%;
    }

    .single-document main {
        margin: 0 auto;
        width: 1000px;
    }
}

article header h1 {
    font-size: 1.7em;
}

article#title header h1 {
    font-size: 2.6rem;
}

article {
    padding: 2rem 0 1rem 0;
    position: relative;
}

article header a h1 {
    cursor: pointer;
}

article div.page-counter {
    display: block;
    text-align: right;
    width: auto;
    height: auto;
    color: #666;
    font-size: .8rem;
    padding: .2rem .5rem .2rem .5rem;
    margin-top: 4rem;
}

article:not(#title):not(:last-of-type) {
    border-bottom: #efefef 1px solid;
}

article#title img {
    width: 160px;
}

article#title nav ul {
    list-style: none;
    padding: 0;
    margin: 0;
}

article#title nav > ul > li a {
    opacity: .9;
    text-decoration: none;
}

article#title nav li > a:hover,
article#title nav li.selected > a {
    opacity: 1;
    font-weight: bold;
}

article#title nav > ul > li a {
    display: block;
    padding: .3rem;
    cursor: pointer;
}

article#title nav > ul > li > a { padding-left: 0rem; padding-right: 0rem; }
article#title nav > ul > li > ul > li > a { padding-left: 1rem; padding-right: 1rem; }
article#title nav > ul > li > ul > li > ul > li > a { padding-left: 2rem; padding-right: 2rem; }
article#title nav > ul > li > ul > li > ul > li > ul > li > a { padding-left: 3rem; padding-right: 3rem; }
article#title nav > ul > li > ul > li > ul > li > ul > li > ul > li > a { padding-left: 4rem; padding-right: 4rem; }
article#title nav > ul > li > ul > li > ul > li > ul > li > ul > li > ul > li > a { padding-left: 5rem; padding-right: 5rem; }

@media screen and (min-width: 56rem) {
    .combined-document article#title {
        position: fixed;
        height: 100%;
        width: 320px;
        left: 0;
        top: 0;
        overflow: auto;
    }

    .combined-document article#title header img {
        width: 100px;
    }

    .combined-document article#title header h1 {
        font-size: 1.2rem;
    }

    .combined-document article#title > header > div {
        display: block;
        width: 100%;
        padding: 0 2rem 1rem 2rem;
        border-bottom: #bbb 1px solid;
    }

    .combined-document article#title nav {
        padding: 2rem 2rem 0 2rem;
        opacity: .6;
        transition: .3s all;
        font-size: .8rem;
    }

    .combined-document article#title nav h1 {
        display: none;
    }

    .combined-document article#title nav:hover {
        opacity: 1;
    }
}

#copyright {
    font-size: 12px;
    color: #ccc;
    padding: 1rem 0 1rem 0;
    margin-top: 1rem;
}



pre {
    table-layout: fixed;
    width: 100%;
    word-wrap: break-word;
    white-space: pre-wrap;
    white-space: -moz-pre-wrap;
    white-space: -pre-wrap;
    white-space: -o-pre-wrap;
    word-wrap: break-word;
}

hr,img,legend {
    border:0;
}

blockquote,h6 {
    color:#777;
}

a,h3,h4,h5,tt {
    color:#333;
}

article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary {
    display:block;
}

a {
    background:0 0;
}

a:focus {
    outline:dotted thin;
}

a:active,a:hover {
    outline:0;
}

abbr[title] {
    border-bottom:1px dotted;
}

hr {
    -moz-box-sizing:content-box;
    box-sizing:content-box;
    background:url('data:image/png; base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC') repeat-x;
    color:#ccc;
    height:4px;
    padding:0;
}

mark {
    background:#ff0;
}

kbd,samp {
    font-family:monospace,serif;
    font-size:1em;
}

q {
    quotes:\201C \201D \2018 \2019;
}

small {
    font-size:80%;
}

sup {
    top:-.5em;
}

sub {
    bottom:-.25em;
    vertical-align:sub;
    top:-1px;
}

img {
    max-width:100%;
}

svg:not(:root) {
    overflow:hidden;
}

figure {
    margin:0;
}

dl dt,h1,h2,h3,h4,h5,h6 {
    font-weight:700;
    padding:0;
}

a:hover {
    text-decoration:underline;
}

h1,h2,h3,h4,h5,h6 {
    cursor:text;
    margin:20px 0 10px;
}

article:not(#title) h1,
article:not(#title) h2,
article:not(#title) h3,
article:not(#title) h4,
article:not(#title) h5 {
    padding: 1rem 0 1rem 0;
}

dl dt,h5,h6 {
    font-size:14px;
}

blockquote,p,table {
    margin:15px 0;
}

ol,ul {
    padding-left:30px;
}

blockquote>:first-child,dl dd>:first-child,dl dt>:first-child,h1+p,h2+p,h3+p,h4+p,h5+p,h6+p,ol li ul:first-of-type,ol li>:first-child,ul li>:first-child {
    margin-top:0;
}

a:first-child h1,a:first-child h2,a:first-child h3,a:first-child h4,a:first-child h5,a:first-child h6,body>h1:first-child,body>h1:first-child+h2,body>h2:first-child,body>h3:first-child,body>h4:first-child,body>h5:first-child,body>h6:first-child {
    margin-top:0;
    padding-top:0;
}

table td,table th {
    border:1px solid #ccc;
    padding:6px 13px;
}

dl dt {
    font-style:italic;
    margin:15px 0 5px;
}

blockquote>:last-child,dl dd>:last-child,dl dt>:last-child {
    margin-bottom:0;
}

dl dd {
    margin:0 0 15px;
    padding:0 15px;
}

blockquote {
    border-left:4px solid #DDD;
    padding:0 15px;
}

table {
    border-collapse:collapse;
    border-spacing:0;
    font:inherit;
    width: 100%;
}

table tr {
    border-top:1px solid #ccc;
    background-color:#fff;
}

a.footnote,sub,sup {
    font-size:1.4ex;
    height:0;
    line-height:1;
    vertical-align:super;
    position:relative;
}


/**
 * Tables
 */
table thead tr {
    background-color: #111111;
    color: #efefef;
}

table th:empty {
    display: none;
}

table th,
table td {
    padding: 1rem;
}

table tbody tr:nth-child(even) {
    background-color: #efefef;
}

/**
 * General
 */
p a {
    font-weight: bold;
}


span.citation {
    font-weight: bold;
    vertical-align: super;
}


.highlight { background-color: #111; color: #efefef; padding: 1rem; }
.highlight .hll { background-color: #222; font-size: 8px; }
.highlight .c { color: #75715e } /* Comment */
.highlight .err { color: #960050; background-color: #1e0010 } /* Error */
.highlight .k { color: #66d9ef } /* Keyword */
.highlight .l { color: #ae81ff } /* Literal */
.highlight .n { color: #f8f8f2 } /* Name */
.highlight .o { color: #f92672 } /* Operator */
.highlight .p { color: #f8f8f2 } /* Punctuation */
.highlight .cm { color: #75715e } /* Comment.Multiline */
.highlight .cp { color: #75715e } /* Comment.Preproc */
.highlight .c1 { color: #75715e } /* Comment.Single */
.highlight .cs { color: #75715e } /* Comment.Special */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .kc { color: #66d9ef } /* Keyword.Constant */
.highlight .kd { color: #66d9ef } /* Keyword.Declaration */
.highlight .kn { color: #f92672 } /* Keyword.Namespace */
.highlight .kp { color: #66d9ef } /* Keyword.Pseudo */
.highlight .kr { color: #66d9ef } /* Keyword.Reserved */
.highlight .kt { color: #66d9ef } /* Keyword.Type */
.highlight .ld { color: #e6db74 } /* Literal.Date */
.highlight .m { color: #ae81ff } /* Literal.Number */
.highlight .s { color: #e6db74 } /* Literal.String */
.highlight .na { color: #a6e22e } /* Name.Attribute */
.highlight .nb { color: #f8f8f2 } /* Name.Builtin */
.highlight .nc { color: #a6e22e } /* Name.Class */
.highlight .no { color: #66d9ef } /* Name.Constant */
.highlight .nd { color: #a6e22e } /* Name.Decorator */
.highlight .ni { color: #f8f8f2 } /* Name.Entity */
.highlight .ne { color: #a6e22e } /* Name.Exception */
.highlight .nf { color: #a6e22e } /* Name.Function */
.highlight .nl { color: #f8f8f2 } /* Name.Label */
.highlight .nn { color: #f8f8f2 } /* Name.Namespace */
.highlight .nx { color: #a6e22e } /* Name.Other */
.highlight .py { color: #f8f8f2 } /* Name.Property */
.highlight .nt { color: #f92672 } /* Name.Tag */
.highlight .nv { color: #f8f8f2 } /* Name.Variable */
.highlight .ow { color: #f92672 } /* Operator.Word */
.highlight .w { color: #f8f8f2 } /* Text.Whitespace */
.highlight .mf { color: #ae81ff } /* Literal.Number.Float */
.highlight .mh { color: #ae81ff } /* Literal.Number.Hex */
.highlight .mi { color: #ae81ff } /* Literal.Number.Integer */
.highlight .mo { color: #ae81ff } /* Literal.Number.Oct */
.highlight .sb { color: #e6db74 } /* Literal.String.Backtick */
.highlight .sc { color: #e6db74 } /* Literal.String.Char */
.highlight .sd { color: #e6db74 } /* Literal.String.Doc */
.highlight .s2 { color: #e6db74 } /* Literal.String.Double */
.highlight .se { color: #ae81ff } /* Literal.String.Escape */
.highlight .sh { color: #e6db74 } /* Literal.String.Heredoc */
.highlight .si { color: #e6db74 } /* Literal.String.Interpol */
.highlight .sx { color: #e6db74 } /* Literal.String.Other */
.highlight .sr { color: #e6db74 } /* Literal.String.Regex */
.highlight .s1 { color: #e6db74 } /* Literal.String.Single */
.highlight .ss { color: #e6db74 } /* Literal.String.Symbol */
.highlight .bp { color: #f8f8f2 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #f8f8f2 } /* Name.Variable.Class */
.highlight .vg { color: #f8f8f2 } /* Name.Variable.Global */
.highlight .vi { color: #f8f8f2 } /* Name.Variable.Instance */
.highlight .il { color: #ae81ff } /* Literal.Number.Integer.Long */

.highlight .gh { } /* Generic Heading & Diff Header */
.highlight .gu { color: #75715e; } /* Generic.Subheading & Diff Unified/Comment? */
.highlight .gd { color: #f92672; } /* Generic.Deleted & Diff Deleted */
.highlight .gi { color: #a6e22e; } /* Generic.Inserted & Diff Inserted */"</style>
<title>SYCL Guide - Memory</title>
<meta charset="utf-8"/>
</head>
<body class="single-document">
<main>
<article id="title">
<header>
<div>
<a href="https://www.codeplay.com" id="logo" style="width: 160px; height: 46px; display: block; " target="_blank">
<img src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 22.1.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Logo" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 379.5 110.6" style="enable-background:new 0 0 379.5 110.6;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#ABD3F1;}
	.st1{fill:#963594;}
	.st2{fill:#5B1D57;}
	.st3{fill:url(#SVGID_1_);}
	.st4{fill:url(#SVGID_2_);}
	.st5{fill:url(#SVGID_3_);}
	.st6{fill:none;stroke:#000000;stroke-miterlimit:10;}
	.st7{fill-rule:evenodd;clip-rule:evenodd;}
	.st8{opacity:0.73;}
</style>
<path class="st0" d="M56.5,40c0,15.6-12.7,28.3-28.5,28.3V11.7C43.8,11.7,56.5,24.4,56.5,40z"/>
<path class="st1" d="M0,40c0-15.6,12.6-28.3,28-28.3v56.6C12.6,68.3,0,55.6,0,40z"/>
<path class="st2" d="M28.1,62c-12.1,0-22-9.8-22-22s9.8-22,22-22V62z"/>
<linearGradient id="SVGID_1_" gradientUnits="userSpaceOnUse" x1="39.0289" y1="61.9821" x2="39.0289" y2="18.0654">
	<stop  offset="0" style="stop-color:#9FCEEF"/>
	<stop  offset="1" style="stop-color:#53B2E5"/>
</linearGradient>
<path class="st3" d="M50,40c0,12.1-9.8,22-22,22V18.1C40.2,18.1,50,27.9,50,40z"/>
<linearGradient id="SVGID_2_" gradientUnits="userSpaceOnUse" x1="21.2323" y1="18.0917" x2="21.2323" y2="61.9821">
	<stop  offset="0" style="stop-color:#C2E8F8"/>
	<stop  offset="1" style="stop-color:#24ABE2"/>
</linearGradient>
<path class="st4" d="M28,62c-7.5,0-13.6-9.8-13.6-22S20.5,18.1,28,18.1V62z"/>
<radialGradient id="SVGID_3_" cx="30.7477" cy="34.8571" r="13.1784" gradientUnits="userSpaceOnUse">
	<stop  offset="0.1399" style="stop-color:#FFFFFF"/>
	<stop  offset="1" style="stop-color:#FFF200"/>
</radialGradient>
<path class="st5" d="M28.3,24.7c-0.4,0-0.7,0.1-1,0.2c-5,0.6-9,7.2-9,15.2c0,8.4,4.4,15.3,9.8,15.3v0c0.1,0-0.1,0,0,0
	c8.5,0,15.5-6.9,15.5-15.3S36.7,24.7,28.3,24.7z"/>
<g>
	<path d="M100.1,26.3l-3.7,6.4c-2-1.9-4.7-2.8-8.1-2.8c-3.2,0-5.8,1.1-7.7,3.2s-2.8,5.1-2.8,8.9c0,7.7,3.7,11.5,11,11.5
		c3.2,0,5.9-1,8.4-3.1l3.1,6.7c-2.5,1.5-4.6,2.5-6.5,2.9s-4,0.6-6.6,0.6c-5.6,0-10.1-1.6-13.4-4.9s-4.9-7.9-4.9-13.7
		c0-5.8,1.8-10.4,5.4-14c3.6-3.5,8.4-5.3,14.6-5.3C93.3,22.7,97,23.9,100.1,26.3z"/>
	<path d="M104.8,41.6c0-5.6,1.6-10.1,4.8-13.6c3.2-3.5,7.5-5.3,12.7-5.3c5.6,0,9.9,1.7,12.9,5.1s4.6,8,4.6,13.8
		c0,5.8-1.6,10.5-4.7,13.9s-7.4,5.2-12.8,5.2c-5.6,0-9.9-1.7-13-5.2C106.4,52,104.8,47.3,104.8,41.6z M113.7,41.6
		c0,8.1,2.9,12.1,8.7,12.1c2.7,0,4.8-1,6.3-3.1c1.6-2.1,2.3-5.1,2.3-8.9c0-7.9-2.9-11.9-8.7-11.9c-2.7,0-4.8,1-6.3,3.1
		C114.5,34.9,113.7,37.8,113.7,41.6z"/>
	<path d="M170.3,59.9v-2.2c-0.7,0.8-1.9,1.5-3.6,2c-1.7,0.6-3.4,0.9-5.2,0.9c-5.1,0-9.1-1.6-12-4.8c-2.9-3.2-4.4-7.7-4.4-13.5
		s1.7-10.5,5-14.1c3.4-3.6,7.6-5.4,12.6-5.4c2.8,0,5.3,0.6,7.6,1.7V9.8l8.5-2v52.2H170.3z M170.3,32.1c-1.8-1.5-3.7-2.2-5.7-2.2
		c-3.4,0-6,1-7.9,3.1s-2.8,5.1-2.8,9c0,7.6,3.7,11.4,11,11.4c0.8,0,1.8-0.2,3-0.7c1.2-0.5,2-1,2.3-1.5V32.1z"/>
	<path d="M220,44.3h-26.1c0.2,2.9,1.2,5.2,3,6.8c1.8,1.6,4.3,2.4,7.4,2.4c3.9,0,6.8-1,8.9-3l3.3,6.5c-3,2.4-7.5,3.7-13.4,3.7
		c-5.6,0-10-1.6-13.2-4.9c-3.2-3.3-4.9-7.8-4.9-13.7c0-5.8,1.8-10.4,5.3-14c3.6-3.6,7.8-5.4,12.8-5.4c5.3,0,9.6,1.6,12.8,4.7
		c3.2,3.2,4.8,7.2,4.8,12.1C220.7,40.6,220.5,42.2,220,44.3z M194.2,37.9h18c-0.6-5.3-3.5-8-8.9-8C198.4,29.8,195.4,32.5,194.2,37.9
		z"/>
	<path d="M235.4,59v15.3h-8.5V23.4h8.5v2.5c2.1-2.1,4.8-3.1,7.9-3.1c11.6,0,17.5,6.4,17.5,19.2c0,6-1.6,10.6-4.8,13.8
		c-3.2,3.2-7.6,4.8-13.2,4.8C240,60.6,237.6,60.1,235.4,59z M235.4,32.3v19.2c1.5,1.3,3.4,1.9,5.4,1.9c3.9,0,6.8-0.9,8.5-2.8
		c1.7-1.9,2.6-4.8,2.6-8.9c0-4.3-0.9-7.4-2.6-9.1c-1.7-1.8-4.5-2.6-8.5-2.6C238.8,29.9,237,30.7,235.4,32.3z"/>
	<path d="M269.7,9.8l8.5-2v41.1c0,4.5,1.3,7.2,4,8.1c-1.3,2.5-3.6,3.8-6.8,3.8c-3.9,0-5.8-2.7-5.8-8.1V9.8z"/>
	<path d="M309.2,56.3c-0.8,1.3-2.1,2.3-4,3.1c-1.9,0.8-3.9,1.2-6,1.2c-3.9,0-7-1-9.3-3c-2.3-2-3.4-4.8-3.4-8.4
		c0-4.2,1.6-7.5,4.8-9.9s7.7-3.6,13.5-3.6c1,0,2.2,0.2,3.5,0.5c0-4.3-2.7-6.5-8.2-6.5c-3.2,0-5.9,0.5-8.1,1.6l-1.8-6.6
		c2.9-1.4,6.4-2.1,10.5-2.1c5.6,0,9.7,1.3,12.3,3.8c2.6,2.5,3.9,7.3,3.9,14.4v7.8c0,4.9,1,7.9,2.9,9.2c-0.7,1.2-1.5,2-2.4,2.3
		c-0.9,0.3-1.9,0.4-3,0.4c-1.2,0-2.3-0.5-3.3-1.4S309.5,57.4,309.2,56.3z M308.4,42.7c-1.5-0.3-2.5-0.4-3.3-0.4
		c-6.7,0-10.1,2.2-10.1,6.6c0,3.3,1.9,4.9,5.7,4.9c5.1,0,7.7-2.6,7.7-7.7V42.7z"/>
	<path d="M342.3,65.8c-0.9,2.4-2.9,4.5-5.9,6.1c-3,1.6-6.5,2.4-10.5,2.4v-7.5c6.6,0,9.9-1.7,9.9-4.9c0-2.2-0.9-5.5-2.7-10
		l-11.4-28.4h8.8l10,25.3l9-25.3h8.8L342.3,65.8z"/>
</g>
<g id="Hand">
	<circle class="st6" cx="372.4" cy="16.3" r="6.6"/>
	<path class="st7" d="M374.2,19.2c0,0,0.9-0.7,1.1-0.8c0,0,0.9-0.5,0.9-0.6c0,0,0.5-0.2,0.2-0.6c0,0-0.5-0.5-1.4,0.3
		c0,0-0.2,0.2-0.3,0.2c0,0-0.8,0.6-0.9,0.5c0,0-0.3-0.5,0-0.9c0,0,0.4-0.6,0.4-0.7c0,0,0.1-0.2,0.3-0.3c0,0,0.4-0.5,0.5-0.6
		c0,0,0.6-0.8,0.6-0.9c0,0,0.1-0.2,0.2-0.3c0,0,0.6-0.9,0.3-1.1c0,0-0.3-0.5-0.8,0.3l-0.2,0.3c0,0-0.2,0.3-0.3,0.4
		c0,0-0.4,0.4-0.5,0.6c0,0-0.5,0.5-0.6,0.7c0,0-0.2,0.2-0.3,0.2c0,0-0.2,0.1,0.1-0.3c0,0,0.5-0.8,0.5-0.9c0,0,0.6-1,0.5-1.1
		c0,0,0.4-0.8,0.4-0.8c0,0,0.3-0.5-0.2-0.7c0,0-0.4,0-0.6,0.6c0,0-0.4,0.7-0.4,0.7c0,0-0.5,0.7-0.5,0.8c0,0-0.7,1-0.8,1.2
		c0,0-0.3,0.2-0.1-0.3c0,0,0.2-0.6,0.2-0.9c0,0,0.3-0.7,0.2-0.8c0,0,0.2-0.2,0.2-0.4c0,0,0.6-0.8,0.2-1c0,0-0.3-0.3-0.7,0.3
		c0,0-0.3,0.5-0.3,0.7c0,0-0.6,1-0.6,1.2c0,0-0.4,1.2-0.5,1.2c0,0-0.4,0.1-0.3-0.3c0,0,0-0.3,0-0.5c0,0,0-0.6,0-0.8
		c0,0,0-0.4,0.1-0.6c0,0,0.2-0.8-0.1-0.9c0,0-0.5-0.2-0.6,1.1c0,0-0.1,0.8-0.1,1c0,0-0.1,1.1-0.1,1.3c0,0-0.5,1.7-0.6,1.7
		c0,0-0.1,0.8-0.1,1.4c0,0,0.1,0.8,1,1.1l0.5,0.4c0,0,0.9,0.4,1.4,0.1C371.8,20.5,373.4,20,374.2,19.2z"/>
</g>
<g class="st8">
	<path d="M74.9,98.3c-0.2,1.9-0.9,3.3-2,4.3c-1.1,1-2.6,1.5-4.5,1.5c-1.3,0-2.5-0.3-3.5-1c-1-0.7-1.8-1.6-2.3-2.8
		c-0.6-1.2-0.8-2.6-0.8-4.1v-2.3c0-1.6,0.3-3,0.8-4.2c0.6-1.2,1.3-2.2,2.4-2.8c1-0.7,2.2-1,3.6-1c1.9,0,3.4,0.5,4.5,1.5
		c1.1,1,1.7,2.4,1.9,4.3h-1.5c-0.4-3-2-4.5-4.9-4.5c-1.6,0-2.9,0.6-3.9,1.8c-1,1.2-1.4,2.9-1.4,5V96c0,2.1,0.5,3.7,1.4,4.9
		c0.9,1.2,2.2,1.8,3.8,1.8c1.6,0,2.8-0.4,3.6-1.1c0.8-0.8,1.3-1.9,1.5-3.4H74.9z"/>
	<path d="M77.5,97c0-1.3,0.2-2.4,0.7-3.4c0.5-1,1.2-1.8,2.1-2.4c0.9-0.6,1.9-0.8,3.1-0.8c1.8,0,3.2,0.6,4.3,1.8
		c1.1,1.2,1.6,2.9,1.6,4.9v0.3c0,1.3-0.2,2.4-0.7,3.4c-0.5,1-1.2,1.8-2.1,2.4c-0.9,0.6-1.9,0.8-3.1,0.8c-1.8,0-3.2-0.6-4.3-1.8
		c-1.1-1.2-1.6-2.9-1.6-4.9V97z M78.9,97.4c0,1.6,0.4,2.9,1.2,3.9c0.8,1,1.9,1.5,3.2,1.5c1.3,0,2.4-0.5,3.2-1.5c0.8-1,1.2-2.3,1.2-4
		V97c0-1-0.2-1.9-0.6-2.8c-0.4-0.8-0.9-1.5-1.6-1.9c-0.7-0.5-1.4-0.7-2.3-0.7c-1.3,0-2.4,0.5-3.2,1.5c-0.8,1-1.2,2.4-1.2,4V97.4z"/>
	<path d="M93.6,90.6l0,2.3c0.5-0.8,1.1-1.4,1.9-1.9c0.7-0.4,1.6-0.6,2.5-0.6c1.4,0,2.5,0.4,3.2,1.2c0.7,0.8,1,2,1,3.6v8.7h-1.5v-8.7
		c0-1.2-0.3-2.1-0.8-2.6c-0.5-0.6-1.3-0.9-2.4-0.9c-0.9,0-1.7,0.3-2.4,0.8c-0.7,0.6-1.2,1.3-1.5,2.3v9h-1.5V90.6H93.6z"/>
	<path d="M107.4,90.6l0,2.3c0.5-0.8,1.1-1.4,1.9-1.9c0.7-0.4,1.6-0.6,2.5-0.6c1.4,0,2.5,0.4,3.2,1.2c0.7,0.8,1,2,1,3.6v8.7h-1.5
		v-8.7c0-1.2-0.3-2.1-0.8-2.6c-0.5-0.6-1.3-0.9-2.4-0.9c-0.9,0-1.7,0.3-2.4,0.8c-0.7,0.6-1.2,1.3-1.5,2.3v9H106V90.6H107.4z"/>
	<path d="M124.8,104.1c-1.1,0-2.1-0.3-3-0.8c-0.9-0.6-1.6-1.3-2.1-2.3c-0.5-1-0.8-2.1-0.8-3.3v-0.5c0-1.3,0.2-2.4,0.7-3.4
		c0.5-1,1.2-1.8,2.1-2.4c0.9-0.6,1.8-0.9,2.9-0.9c1.6,0,2.9,0.5,3.8,1.6c0.9,1.1,1.4,2.6,1.4,4.5v0.8h-9.4v0.3
		c0,1.5,0.4,2.7,1.3,3.7c0.9,1,1.9,1.5,3.2,1.5c0.8,0,1.5-0.1,2.1-0.4c0.6-0.3,1.1-0.7,1.6-1.4l0.9,0.7
		C128.4,103.3,126.9,104.1,124.8,104.1z M124.6,91.6c-1.1,0-2,0.4-2.8,1.2c-0.8,0.8-1.2,1.9-1.4,3.2h7.9v-0.2c0-1.3-0.4-2.3-1.1-3.1
		S125.7,91.6,124.6,91.6z"/>
	<path d="M137.5,102.8c1,0,1.9-0.3,2.6-0.9c0.7-0.6,1.1-1.3,1.1-2.2h1.4c0,0.8-0.3,1.5-0.8,2.2s-1.1,1.2-1.8,1.6
		c-0.8,0.4-1.6,0.6-2.5,0.6c-1.7,0-3.1-0.6-4.1-1.8c-1-1.2-1.5-2.8-1.5-4.9V97c0-1.3,0.2-2.5,0.7-3.5c0.5-1,1.1-1.8,2-2.3
		c0.9-0.5,1.8-0.8,3-0.8c1.4,0,2.6,0.4,3.6,1.3c0.9,0.9,1.4,2,1.5,3.4h-1.4c-0.1-1-0.4-1.9-1.1-2.5c-0.7-0.6-1.5-1-2.6-1
		c-1.3,0-2.3,0.5-3.1,1.4c-0.7,1-1.1,2.3-1.1,4v0.4c0,1.7,0.4,3,1.1,3.9C135.2,102.4,136.2,102.8,137.5,102.8z"/>
	<path d="M147.8,87.2v3.4h2.7v1.2h-2.7v8.8c0,0.7,0.1,1.3,0.4,1.6c0.3,0.4,0.7,0.5,1.3,0.5c0.2,0,0.6,0,1.2-0.1l0.1,1.2
		c-0.4,0.1-0.9,0.2-1.6,0.2c-1,0-1.7-0.3-2.2-0.9c-0.5-0.6-0.7-1.4-0.7-2.6v-8.8h-2.4v-1.2h2.4v-3.4H147.8z"/>
	<path d="M153.5,86.8c0-0.3,0.1-0.5,0.3-0.7c0.2-0.2,0.4-0.3,0.7-0.3c0.3,0,0.6,0.1,0.7,0.3c0.2,0.2,0.3,0.4,0.3,0.7
		c0,0.3-0.1,0.5-0.3,0.7c-0.2,0.2-0.4,0.3-0.7,0.3c-0.3,0-0.6-0.1-0.7-0.3C153.6,87.3,153.5,87.1,153.5,86.8z M155.2,103.8h-1.5
		V90.6h1.5V103.8z"/>
	<path d="M160.5,90.6l0,2.3c0.5-0.8,1.1-1.4,1.9-1.9c0.7-0.4,1.6-0.6,2.5-0.6c1.4,0,2.5,0.4,3.2,1.2c0.7,0.8,1,2,1,3.6v8.7h-1.5
		v-8.7c0-1.2-0.3-2.1-0.8-2.6c-0.5-0.6-1.3-0.9-2.4-0.9c-0.9,0-1.7,0.3-2.4,0.8c-0.7,0.6-1.2,1.3-1.5,2.3v9h-1.5V90.6H160.5z"/>
	<path d="M172.3,97.1c0-2.1,0.5-3.7,1.4-4.9c0.9-1.2,2.2-1.8,3.7-1.8c1.8,0,3.2,0.7,4.1,2.1l0.1-1.9h1.4v12.9c0,1.7-0.5,3-1.4,4
		s-2.2,1.5-3.9,1.5c-0.9,0-1.8-0.2-2.6-0.6c-0.8-0.4-1.5-1-2-1.6l0.8-0.9c1,1.3,2.3,1.9,3.7,1.9c1.2,0,2.2-0.4,2.9-1.1
		c0.7-0.7,1-1.7,1.1-3v-1.7c-0.9,1.3-2.3,2-4.1,2c-1.5,0-2.8-0.6-3.7-1.8s-1.4-2.9-1.4-4.9V97.1z M173.8,97.3c0,1.7,0.3,3,1,4
		c0.7,1,1.6,1.5,2.9,1.5c1.8,0,3.1-0.8,3.8-2.4v-6.1c-0.3-0.8-0.8-1.5-1.5-1.9c-0.6-0.4-1.4-0.7-2.3-0.7c-1.2,0-2.2,0.5-2.9,1.4
		C174.1,94,173.8,95.5,173.8,97.3z"/>
	<path d="M202.8,98.8h-8.1l-1.8,5h-1.6L198,86h1.4l6.7,17.8h-1.6L202.8,98.8z M195.2,97.6h7.1l-3.6-9.7L195.2,97.6z"/>
	<path d="M210.6,103.8h-1.5V86h1.5V103.8z"/>
	<path d="M223.4,87.2v3.4h2.7v1.2h-2.7v8.8c0,0.7,0.1,1.3,0.4,1.6s0.7,0.5,1.3,0.5c0.2,0,0.6,0,1.2-0.1l0.1,1.2
		c-0.4,0.1-0.9,0.2-1.6,0.2c-1,0-1.7-0.3-2.2-0.9c-0.5-0.6-0.7-1.4-0.7-2.6v-8.8h-2.4v-1.2h2.4v-3.4H223.4z"/>
	<path d="M228.2,97c0-1.3,0.2-2.4,0.7-3.4s1.2-1.8,2.1-2.4c0.9-0.6,1.9-0.8,3.1-0.8c1.8,0,3.2,0.6,4.3,1.8c1.1,1.2,1.6,2.9,1.6,4.9
		v0.3c0,1.3-0.2,2.4-0.7,3.4c-0.5,1-1.2,1.8-2.1,2.4s-1.9,0.8-3.1,0.8c-1.8,0-3.2-0.6-4.3-1.8c-1.1-1.2-1.6-2.9-1.6-4.9V97z
		 M229.6,97.4c0,1.6,0.4,2.9,1.2,3.9c0.8,1,1.9,1.5,3.2,1.5c1.3,0,2.4-0.5,3.2-1.5c0.8-1,1.2-2.3,1.2-4V97c0-1-0.2-1.9-0.6-2.8
		s-0.9-1.5-1.6-1.9c-0.7-0.5-1.4-0.7-2.3-0.7c-1.3,0-2.4,0.5-3.2,1.5c-0.8,1-1.2,2.4-1.2,4V97.4z"/>
	<path d="M259.4,99.4c0-1-0.3-1.8-1-2.3c-0.7-0.6-2-1.1-3.8-1.6c-1.8-0.5-3.2-1.1-4-1.7c-1.2-0.9-1.8-2-1.8-3.4
		c0-1.4,0.6-2.5,1.7-3.3c1.1-0.9,2.5-1.3,4.3-1.3c1.2,0,2.2,0.2,3.2,0.7c0.9,0.5,1.7,1.1,2.2,1.9c0.5,0.8,0.8,1.7,0.8,2.7h-1.5
		c0-1.2-0.4-2.2-1.2-2.9c-0.8-0.7-1.9-1.1-3.3-1.1c-1.4,0-2.4,0.3-3.2,0.9c-0.8,0.6-1.2,1.4-1.2,2.4c0,0.9,0.4,1.6,1.1,2.2
		c0.7,0.6,1.9,1.1,3.5,1.5c1.6,0.4,2.8,0.9,3.6,1.4c0.8,0.5,1.4,1,1.9,1.7c0.4,0.7,0.6,1.4,0.6,2.3c0,1.4-0.6,2.5-1.7,3.4
		c-1.1,0.8-2.6,1.3-4.4,1.3c-1.3,0-2.4-0.2-3.4-0.7s-1.8-1.1-2.4-1.9c-0.5-0.8-0.8-1.7-0.8-2.8h1.5c0,1.3,0.5,2.2,1.4,3
		c0.9,0.7,2.2,1.1,3.7,1.1c1.4,0,2.5-0.3,3.3-0.9C259,101.3,259.4,100.5,259.4,99.4z"/>
	<path d="M263.8,86.8c0-0.3,0.1-0.5,0.3-0.7s0.4-0.3,0.7-0.3s0.6,0.1,0.7,0.3c0.2,0.2,0.3,0.4,0.3,0.7c0,0.3-0.1,0.5-0.3,0.7
		c-0.2,0.2-0.4,0.3-0.7,0.3s-0.6-0.1-0.7-0.3S263.8,87.1,263.8,86.8z M265.5,103.8H264V90.6h1.5V103.8z"/>
	<path d="M271.1,103.8h-1.5V85.1h1.5V103.8z"/>
	<path d="M275,86.8c0-0.3,0.1-0.5,0.3-0.7s0.4-0.3,0.7-0.3s0.6,0.1,0.7,0.3c0.2,0.2,0.3,0.4,0.3,0.7c0,0.3-0.1,0.5-0.3,0.7
		c-0.2,0.2-0.4,0.3-0.7,0.3s-0.6-0.1-0.7-0.3S275,87.1,275,86.8z M276.7,103.8h-1.5V90.6h1.5V103.8z"/>
	<path d="M285.5,102.8c1,0,1.9-0.3,2.6-0.9c0.7-0.6,1.1-1.3,1.1-2.2h1.4c0,0.8-0.3,1.5-0.8,2.2s-1.1,1.2-1.8,1.6
		c-0.8,0.4-1.6,0.6-2.5,0.6c-1.7,0-3.1-0.6-4.1-1.8c-1-1.2-1.5-2.8-1.5-4.9V97c0-1.3,0.2-2.5,0.7-3.5s1.1-1.8,2-2.3
		c0.9-0.5,1.8-0.8,3-0.8c1.4,0,2.6,0.4,3.6,1.3c0.9,0.9,1.4,2,1.5,3.4h-1.4c-0.1-1-0.4-1.9-1.1-2.5s-1.5-1-2.6-1
		c-1.3,0-2.3,0.5-3.1,1.4s-1.1,2.3-1.1,4v0.4c0,1.7,0.4,3,1.1,3.9C283.2,102.4,284.2,102.8,285.5,102.8z"/>
	<path d="M292.7,97c0-1.3,0.2-2.4,0.7-3.4s1.2-1.8,2.1-2.4c0.9-0.6,1.9-0.8,3.1-0.8c1.8,0,3.2,0.6,4.3,1.8c1.1,1.2,1.6,2.9,1.6,4.9
		v0.3c0,1.3-0.2,2.4-0.7,3.4c-0.5,1-1.2,1.8-2.1,2.4s-1.9,0.8-3.1,0.8c-1.8,0-3.2-0.6-4.3-1.8c-1.1-1.2-1.6-2.9-1.6-4.9V97z
		 M294.2,97.4c0,1.6,0.4,2.9,1.2,3.9c0.8,1,1.9,1.5,3.2,1.5c1.3,0,2.4-0.5,3.2-1.5c0.8-1,1.2-2.3,1.2-4V97c0-1-0.2-1.9-0.6-2.8
		s-0.9-1.5-1.6-1.9c-0.7-0.5-1.4-0.7-2.3-0.7c-1.3,0-2.4,0.5-3.2,1.5c-0.8,1-1.2,2.4-1.2,4V97.4z"/>
	<path d="M308.9,90.6l0,2.3c0.5-0.8,1.1-1.4,1.9-1.9c0.7-0.4,1.6-0.6,2.5-0.6c1.4,0,2.5,0.4,3.2,1.2c0.7,0.8,1,2,1,3.6v8.7H316v-8.7
		c0-1.2-0.3-2.1-0.8-2.6c-0.5-0.6-1.3-0.9-2.4-0.9c-0.9,0-1.7,0.3-2.4,0.8c-0.7,0.6-1.2,1.3-1.5,2.3v9h-1.5V90.6H308.9z"/>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
</svg>
"/>
</a>
<h1>SYCL Guide - Memory</h1>
</div>
</header>
</article>
<a class="header-link" href="#memory-and-synchronization" id="memory-and-synchronization"><h1>Memory and synchronization</h1></a>
<p>While for simple computations it is okay to operate purely on work-items, any more complex workload will require finer-grained control. Unfortunately, this comes at the cost of introducing some complexity. Hopefully though, we can clear everything up!</p>
<p>You might remember that work-items are grouped into work-groups. The splitting into work-groups is not purely conceptual - it has very real implications on memory accesses and performance. Work-groups are independent of each other. In fact, there is no way to synchronize between them in a single kernel. For this reason, two work-groups should never write to the same memory location (although they can read shared data).</p>
<p>OpenCL and SYCL define a clear distinction between various regions in memory and rules that govern accesses to these. Everything on the CPU side is known as <strong>host memory</strong>. It is not directly accessible from kernels, but as we've seen, buffers and accessors provide facilities for copying host data to the device and accessing it there. The corresponding accessor target is <code>access::target::host_buffer</code>.</p>
<p>On the device side, more memory regions exist:</p>
<ul>
<li><strong>Global memory</strong> is available in the same form to all work-groups and items. It can be thought of as a device-side equivalent of RAM. 
The corresponding target, <code>access::target::global_buffer</code>, is the default target for <code>buffer::get_access</code>. 
In previous examples we didn't explicitly specify a target, so this one was used.</li>
<li><strong>Local memory</strong> is specific to a single work-group. Work-groups cannot access others' local memory, but it is shared between all work-items in a group. 
It can be thought of as a user-controlled cache. It is especially useful for divide-and-conquer problems where each part of computation is handled by one work-group. 
Local memory can be used to store the result of such a computation. 
Local memory is allocated per kernel execution and it cannot be filled with host data, so you have to initialize it yourself. 
The canonical way to allocate it is to create a <code>access::target::local</code> accessor inside a command group, passing it the requested allocation size.</li>
<li><strong>Private memory</strong> is a small region dedicated to each work-item. It is much like CPU register memory. 
All variables created in a kernel are stored in private memory. Additionally, dedicated <code>private_memory</code> objects can be created for this purpose.</li>
<li>Finally, <strong>constant memory</strong> is a read-only part of global memory, which similarly can reference a host-side buffer.</li>
</ul>
<p>In this example we will try to compute a vector reduction - the sum of all its elements. 
The overall structure of the example is as follows:</p>
<p><strong>Parallel reduction</strong></p>
<pre><code class="cpp"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span><span class="cp"></span>
<span class="w">  </span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdint&gt;</span><span class="cp"></span>
<span class="w">  </span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>
<span class="w">  </span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;random&gt;</span><span class="cp"></span>
<span class="w">  </span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span><span class="cp"></span>

<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">int_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">int32_t</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="k">class</span> <span class="nc">reduction_kernel</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">int_type</span><span class="o">&gt;</span><span class="w"> </span><span class="n">vec</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">mt19937</span><span class="w"> </span><span class="n">mt_engine</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">random_device</span><span class="p">{}());</span><span class="w"></span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">uniform_int_distribution</span><span class="o">&lt;</span><span class="n">int_type</span><span class="o">&gt;</span><span class="w"> </span><span class="n">idist</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"Data: "</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="nl">el</span> <span class="p">:</span><span class="w"> </span><span class="n">vec</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">      </span><span class="n">el</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">idist</span><span class="p">(</span><span class="n">mt_engine</span><span class="p">);</span><span class="w"></span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">el</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">" "</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">int_type</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">accumulate</span><span class="p">(</span><span class="n">vec</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">vec</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="o">&lt;&lt;</span><span class="n">Read</span><span class="w"> </span><span class="n">hardware</span><span class="w"> </span><span class="n">information</span><span class="o">&gt;&gt;</span><span class="w"></span>

<span class="w">    </span><span class="o">&lt;&lt;</span><span class="n">Reduction</span><span class="w"> </span><span class="n">loop</span><span class="o">&gt;&gt;</span><span class="w"></span>

<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"Sum: "</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">vec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"Reference sum: "</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">vec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">sum</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
</pre></div>
</code></pre>
<p>The first thing we do is initialize a vector of random values to be added together and a buffer for that data. 
We then print the values. And compute a reference sum using <code>std::accumulate</code>.</p>
<p><strong>Read hardware information</strong></p>
<pre><code class="cpp"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">device</span><span class="p">{</span><span class="n">sycl</span><span class="o">::</span><span class="n">default_selector</span><span class="p">{}};</span><span class="w"></span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="nf">queue</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="p">[](</span><span class="k">const</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">exception_list</span><span class="o">&amp;</span><span class="w"> </span><span class="n">el</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="nl">ex</span> <span class="p">:</span><span class="w"> </span><span class="n">el</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">rethrow_exception</span><span class="p">(</span><span class="n">ex</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="p">});</span><span class="w"></span>

<span class="w">  </span><span class="c1">// Make sure the size is not too large</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">wgroup_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">min</span><span class="p">(</span><span class="n">device</span><span class="p">.</span><span class="n">get_info</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">info</span><span class="o">::</span><span class="n">device</span><span class="o">::</span><span class="n">max_work_group_size</span><span class="o">&gt;</span><span class="p">(),</span><span class="w"> </span><span class="n">vec</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">vec</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">2</span><span class="p">));</span><span class="w"> </span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">wgroup_size</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">throw</span><span class="w"> </span><span class="s">"Work-group size has to be even!"</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">part_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wgroup_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">has_local_mem</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">is_host</span><span class="p">()</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="p">(</span><span class="n">device</span><span class="p">.</span><span class="n">get_info</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">info</span><span class="o">::</span><span class="n">device</span><span class="o">::</span><span class="n">local_mem_type</span><span class="o">&gt;</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">info</span><span class="o">::</span><span class="n">local_mem_type</span><span class="o">::</span><span class="n">none</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">local_mem_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device</span><span class="p">.</span><span class="n">get_info</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">info</span><span class="o">::</span><span class="n">device</span><span class="o">::</span><span class="n">local_mem_size</span><span class="o">&gt;</span><span class="p">();</span><span class="w"></span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">has_local_mem</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">local_mem_size</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">wgroup_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">int_type</span><span class="p">)))</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">throw</span><span class="w"> </span><span class="s">"Device doesn't have enough local memory!"</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
</pre></div>
</code></pre>
<p>We use the <code>default_selector</code> to get a device. This allows us to access hardware information. Then we will make a <code>queue</code> on this device. You might want to change the default selector for something more precise like a <code>cpu_selector</code> or <code>host_selector</code>, depending on your setup.</p>
<p>The <code>device::get_info</code> function has a single template parameter specifying the piece of information that we want to retrieve. <code>info::device::max_work_group_size</code> is defined to be the maximum number of work-items in a work-group executing on a single compute unit. Exceeding this size should result in an error. It is not necessarily the optimal size, but it can be expected to yield good performance. We take the minimum between this value and the work size padded to the next even integer.</p>
<p>We initialize a <code>part_size</code> variable to be the number of elements in the vector that work-group reduces. Since each work-item initially reduces two elements, it is twice the work-group size.</p>
<p>We also test the device for the local memory size - we cannot perform the reduction if there is too little of it or if local memory is unsupported altogether. Of course, in a real-world application a special case would have to be made to also support such devices.</p>
<p><strong>Reduction loop</strong></p>
<pre><code class="cpp"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">len</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vec</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"></span>
<span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">len</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="c1">// division rounding up</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">n_wgroups</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">len</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">part_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">len</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">part_size</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">int_type</span><span class="o">&gt;</span><span class="w"> </span><span class="n">tmp</span><span class="p">(</span><span class="n">n_wgroups</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="n">int_type</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">buf</span><span class="p">(</span><span class="n">vec</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">vec</span><span class="p">.</span><span class="n">size</span><span class="p">()));</span><span class="w"></span>
<span class="w">    </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="n">int_type</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">tmp_buf</span><span class="p">(</span><span class="n">tmp</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">tmp</span><span class="p">.</span><span class="n">size</span><span class="p">()));</span><span class="w"></span>
<span class="w">    </span><span class="n">queue</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">      </span><span class="n">sycl</span><span class="o">::</span><span class="n">accessor</span><span class="o">&lt;</span><span class="n">int_type</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">access</span><span class="o">::</span><span class="n">mode</span><span class="o">::</span><span class="n">read_write</span><span class="p">,</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">access</span><span class="o">::</span><span class="n">target</span><span class="o">::</span><span class="n">local</span><span class="o">&gt;</span><span class="w"> </span><span class="n">local_mem</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">wgroup_size</span><span class="p">),</span><span class="w"> </span><span class="n">cgh</span><span class="p">);</span><span class="w"></span>
<span class="w">      </span><span class="k">auto</span><span class="w"> </span><span class="n">global_mem</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">buf</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">access</span><span class="o">::</span><span class="n">mode</span><span class="o">::</span><span class="n">read</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span><span class="w"></span>
<span class="w">      </span><span class="k">auto</span><span class="w"> </span><span class="n">global_tmp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tmp_buf</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">sycl</span><span class="o">::</span><span class="n">access</span><span class="o">::</span><span class="n">mode</span><span class="o">::</span><span class="n">write</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span><span class="w"></span>
<span class="w">      </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">reduction_kernel</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">nd_range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">n_wgroups</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">wgroup_size</span><span class="p">,</span><span class="w"> </span><span class="n">wgroup_size</span><span class="p">),</span><span class="w"></span>
<span class="w">        </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">nd_item</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">item</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">          </span><span class="o">&lt;&lt;</span><span class="n">Perform</span><span class="w"> </span><span class="n">load</span><span class="w"> </span><span class="n">into</span><span class="w"> </span><span class="n">local</span><span class="w"> </span><span class="n">memory</span><span class="o">&gt;&gt;</span><span class="w"></span>

<span class="w">          </span><span class="o">&lt;&lt;</span><span class="n">Reduce</span><span class="w"> </span><span class="n">into</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">element</span><span class="o">&gt;&gt;</span><span class="w"></span>

<span class="w">          </span><span class="o">&lt;&lt;</span><span class="n">Write</span><span class="w"> </span><span class="n">group</span><span class="w"> </span><span class="n">result</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">global_tmp</span><span class="w"> </span><span class="n">memory</span><span class="o">&gt;&gt;</span><span class="w"></span>
<span class="w">        </span><span class="p">});</span><span class="w"></span>
<span class="w">      </span><span class="p">}).</span><span class="n">wait_and_throw</span><span class="p">();</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">swap</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span><span class="w"> </span><span class="n">tmp</span><span class="p">);</span><span class="w"> </span><span class="c1">// We swap the vectors to avoid copying memory</span>
<span class="w">  </span><span class="n">len</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_wgroups</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</code></pre>
<p>Inside the reduction loop, we first find the number of work-groups for this step of reduction. It is the length <code>len</code> left to be reduced divided by the number of elements that each work-group reduces.</p>
<p>Next, in the command group, we allocate a part of local memory by creating an accessor with <code>access::target::local</code> and a range equal to the work-group size. We checked the memory size earlier, so we know that it is available. As stated above, this region of memory looks different to each work-group and its use is for temporary storage.</p>
<p>You might wonder, why do we even bother with using local memory when we could carry out the whole operation in global? The answer is that it is much faster. Local memory is (usually) physically closer to the chip than global and it does not suffer from problems such as false sharing, since it is exclusive to each compute unit. It is therefore a good idea to always carry out all temporary operations in local memory for best performance.</p>
<p>We also obtain an accessor to the data available in global memory. This time <code>get_access</code> is explicitly qualified with <code>access::target::global_buffer</code>, while previously it took on that value by default.</p>
<p>Lastly, we launch a parallel kernel. We use the <code>nd_range</code> variant, which allows us to specify both the global and local size. The <code>nd_range</code> constructor takes in two <code>range</code> objects of the same dimensionality as itself. The first one describes the number of work-items per dimension (recall that there can be up to three dimensions). The second range argument to <code>nd_range&lt;n&gt;</code> describes the number of work-items in a work-group. To find the number of work-groups per dimension, divide the first argument by the second. In this case the result is <code>n_wgroups</code>, which is how many work-groups will be instantiated. In this variant the kernel lambda takes an <code>nd_item</code> argument. It represents the current work-item and features methods to get detailed information from it, such as local, global, and work-group info.</p>
<p>Since each step of the reduction loop produces one number per work-group, we set the <code>len</code> to <code>n_wgroups</code> on every iteration, which will continue reducing over the results.</p>
<p><strong>Perform load into local memory</strong></p>
<pre><code class="cpp"><div class="highlight"><pre><span></span><span class="kt">size_t</span><span class="w"> </span><span class="n">local_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_local_linear_id</span><span class="p">();</span><span class="w"></span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">global_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">get_global_linear_id</span><span class="p">();</span><span class="w"></span>

<span class="w">  </span><span class="n">local_mem</span><span class="p">[</span><span class="n">local_id</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">((</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">global_id</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">len</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">local_mem</span><span class="p">[</span><span class="n">local_id</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">global_mem</span><span class="p">[</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">global_id</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">global_mem</span><span class="p">[</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">global_id</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">];</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>

<span class="w">  </span><span class="n">item</span><span class="p">.</span><span class="n">barrier</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">access</span><span class="o">::</span><span class="n">fence_space</span><span class="o">::</span><span class="n">local_space</span><span class="p">);</span><span class="w"></span>
</pre></div>
</code></pre>
<p>In the kernel, we firstly zero-initialize the local memory, since it can in fact contain garbage data. The key point here is that 0 is the invariant of our reduction, meaning that <code>x + 0 = x</code>, so we can add the whole vector safely even if it isn't entirely filled with data to be reduced.</p>
<p>We divide our data into parts, each one being computed by a single work-group. The input data is required to be of even size, but it doesn't have to be a multiple of the work-group size. Hence, a few work-items in the last work-group can have no corresponding data. For this reason, the initial load from global to local memory is guarded by an if-statement. As mentioned in the "parallelism" section, this is usually a bad idea. In this case, however, it is okay, because at most one work-group will have divergent work-items. We use a small vector for illustration purposes and a specialized kernel would technically be faster, but any real use case can be expected to have much more input data.</p>
<p>After the load is performed with an addition of the two elements corresponding to each work-item, we emit a <strong>barrier</strong> with a local memory fence. We have to stop for a bit and understand why this is necessary. In the OpenCL memory model, all operations across work-items have relaxed semantics. For example, in the following pseudocode we execute two functions in parallel over the same data:</p>
<p><strong>Relaxed write</strong></p>
<pre><code class="c++"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">thread_a</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">write</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">write</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">thread_b</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">ly</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">load</span><span class="p">(</span><span class="n">y</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">lx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">load</span><span class="p">(</span><span class="n">x</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">"%i %i"</span><span class="p">,</span><span class="w"> </span><span class="n">lx</span><span class="p">,</span><span class="w"> </span><span class="n">ly</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>

<span class="w">  </span><span class="n">in_parallel</span><span class="p">(</span><span class="n">thread_a</span><span class="p">,</span><span class="w"> </span><span class="n">thread_b</span><span class="p">);</span><span class="w"></span>
</pre></div>
</code></pre>
<p>In a relaxed memory model, work-item B can in fact print <code>0 2</code>. This looks wrong, because work-item A must have written <code>x</code> into memory before it wrote <code>y</code>. The key point is that operation work-item B can observe A's operations in a different order. This 'really' helps hardware performance, but it comes at the cost of confusing behaviour. To deal with this problem, we have to emit memory fences. Moreover, even if we don't mind reordering, we might want to make sure that all results of write operations propagate between work-items - otherwise they could stay in per-work-item cache and not be visible across work-items.</p>
<p>To synchronize the state of memory, we use the <code>item::barrier(access::fence_space)</code> operation. A SYCL barrier does two things. Firstly, it makes sure that each work-item within the work-group reaches the barrier call. In other words, it guarantees that the work-group is synchronized at a certain point in the code. It is very important to make sure that 'either all work-items reach the barrier or none do'. For example, the following code is <strong>invalid</strong>:</p>
<p><strong>Branch barrier</strong></p>
<pre><code class="cpp"><div class="highlight"><pre><span></span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">local_id</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">item</span><span class="p">.</span><span class="n">barrier</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">access</span><span class="o">::</span><span class="n">fence_space</span><span class="o">::</span><span class="n">local_space</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">item</span><span class="p">.</span><span class="n">barrier</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">access</span><span class="o">::</span><span class="n">fence_space</span><span class="o">::</span><span class="n">local_space</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
</pre></div>
</code></pre>
<p>It looks innocent, but the problem is that the two instructions are not the same barrier. Work-items below local id 5 will get to the first barrier while the rest will get to the other one, and the execution will stall, both groups waiting on each other forever. A simple transformation of factoring the barrier call out of the conditional would fix it.</p>
<p>Secondly, <code>item::barrier</code> emits a memory fence in the specified space. It can be either <code>access::fence_space::local_space</code>, <code>::global_space</code> or <code>::global_and_local</code>. A fence ensures that the state of the specified space is consistent across all work-items within the work-group. Importantly, it is 'not possible' to synchronize between work-groups. They are entirely independent, and any write or read in the same global memory area done by two work-groups is a data race. For this reason, it is important to make sure each work-group only works on a dedicated region of global memory without crossover.</p>
<p>Next, we reduce each work-group's vector in local memory:</p>
<p><strong>Reduce into one element</strong></p>
<pre><code class="cpp"><div class="highlight"><pre><span></span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">wgroup_size</span><span class="p">;</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">local_id</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">wgroup_size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">      </span><span class="n">local_mem</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">local_mem</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">local_mem</span><span class="p">[</span><span class="n">idx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">stride</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="n">item</span><span class="p">.</span><span class="n">barrier</span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">access</span><span class="o">::</span><span class="n">fence_space</span><span class="o">::</span><span class="n">local_space</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
</pre></div>
</code></pre>
<p>Since each iteration of the <code>for</code> loop depends on the previous one, we emit a barrier every time to synchronise work-items.</p>
<p>Lastly, write a single number which is the result of this work-group's reduction into a temporary global memory buffer.</p>
<p><strong>Write group result to global memory</strong></p>
<pre><code class="cpp"><div class="highlight"><pre><span></span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">local_id</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">global_tmp</span><span class="p">[</span><span class="n">item</span><span class="p">.</span><span class="n">get_group_linear_id</span><span class="p">()]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">local_mem</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
</pre></div>
</code></pre>
<p>We have to use a temporary buffer as we cannot ensure all work-groups are working in parallel as previously explained. Writing to the original memory could produce
a data race as some work-groups could be loading data just written by others. A solution would be to create a "device-wide" barrier, but that it not recommended nor is in the SYCL specification.</p>
<p>Finally we leave the scope where the buffers are created so memory is synchronised. Then we swap the temporary vector with the one containing previous data. </p>
<p>And the result is obtained:</p>
<p>Data: 1 8 5 9 4 2 6 0 1 8 6 2 10 9 0 5
Sum: 76
Reference sum: 76</p>
<div id="copyright">SYCL is a trademark of the Khronos Group Inc. OpenCL and the OpenCL logo are trademarks of Apple Inc. used by permission by Khronos.</div>
</main>
</body>
</html>
